{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bfc83e1",
   "metadata": {},
   "source": [
    "# Functional Analysis Plots\n",
    "### CAZyme, COG, and AMR visualizations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c9127",
   "metadata": {},
   "source": [
    "This notebook generates publication-ready plots from functional annotation feature tables (QIIME2 artifacts) and associated sample metadata.\n",
    "\n",
    "It focuses on:\n",
    "- CAZyme class composition and CAZy family-level patterns\n",
    "- COG composition\n",
    "- AMR total burden summaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a805a9",
   "metadata": {},
   "source": [
    "#### **Goal**\n",
    "\n",
    "Create a consistent set of figures in `figures/` for downstream reporting:\n",
    "- CAZyme class composition (stacked bars / clustering)\n",
    "- CAZy family PCA and top-family dotplots\n",
    "- COG composition plots\n",
    "- AMR burden summaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9538b5",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red; padding:10px; color:#b30000;\">\n",
    "<b>Note</b><br>\n",
    "This notebook assumes the required QIIME2 `.qza` artifacts and the merged metadata table are already present under <code>data/07_Functional_analysis/</code>.\n",
    "Several plotting steps depend on mapping functions (<code>id_to_sample</code>, <code>id_to_food</code>) created in <b>Step 1</b>, so run cells in order.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea1444",
   "metadata": {},
   "source": [
    "#### **Notebook Content:** ####\n",
    "- [Prepare Environment](#prepare-environment)\n",
    "- [Step 1. Build sample/food mapping](#step-1-build-samplefood-mapping)\n",
    "- [Step 2. Export CAZ annotation feature table](#step-2-export-caz-annotation-feature-table)\n",
    "- [Step 3. CAZyme class composition](#step-3-cazyme-class-composition)\n",
    "- [Step 4. CAZy family PCA](#step-4-cazy-family-pca)\n",
    "- [Step 5. Top CAZy families dot plot](#step-5-top-cazy-families-dot-plot)\n",
    "- [Step 6. COG functional composition](#step-6-cog-functional-composition)\n",
    "- [Step 7. AMR total burden by sample](#step-7-amr-total-burden-by-sample)\n",
    "- [Step 8. AMR additional summaries](#step-8-amr-additional-summaries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68b7af",
   "metadata": {},
   "source": [
    "### **The workflow** ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f497eb",
   "metadata": {},
   "source": [
    "### Prepare Environment\n",
    "#### Import packages and create local folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26917fbb-f3e1-46d9-992c-3ea312fc2465",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: line 1: data_dir: command not found\n"
     ]
    }
   ],
   "source": [
    "#set up environment\n",
    "import pandas as pd\n",
    "import qiime2 as q2\n",
    "from qiime2 import Visualization\n",
    "\n",
    "# create directories for the notebook. DO NOT change\n",
    "data_dir = 'data/07_Functional_analysis'\n",
    "!data_dir = 'data/07_Functional_analysis'\n",
    "\n",
    "!mkdir -p data\n",
    "!mkdir -p $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149e7c7e",
   "metadata": {},
   "source": [
    "#### Download input artifacts (if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5508f43c-ef92-4d70-b5e4-0cd8eb14fc8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-18 22:59:13--  https://polybox.ethz.ch/index.php/s/WaSKZs2E5xn9SHm/download\n",
      "Resolving polybox.ethz.ch (polybox.ethz.ch)... 129.132.71.243\n",
      "Connecting to polybox.ethz.ch (polybox.ethz.ch)|129.132.71.243|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘data/Download.zip’\n",
      "\n",
      "data/Download.zip       [    <=>             ] 310.65M   406MB/s    in 0.8s    \n",
      "\n",
      "2025-12-18 22:59:14 (406 MB/s) - ‘data/Download.zip’ saved [325735603]\n",
      "\n",
      "Archive:  data/Download.zip\n",
      "   creating: data/07_Functional_analysis/Euler_scripts/\n",
      " extracting: data/07_Functional_analysis/Euler_scripts/annotate_bacteria_95.sh  \n",
      " extracting: data/07_Functional_analysis/Euler_scripts/gunc_bacteria_95.sh  \n",
      " extracting: data/07_Functional_analysis/Euler_scripts/q2_gunc_db.sh  \n",
      " extracting: data/07_Functional_analysis/Euler_scripts/rgi_bacteria_95.sh  \n",
      "   creating: data/07_Functional_analysis/data/\n",
      " extracting: data/07_Functional_analysis/data/bacteria_95_gunc_results.qzv  \n",
      " extracting: data/07_Functional_analysis/data/caz_annot_ft_bacteria_95.qzv  \n",
      " extracting: data/07_Functional_analysis/data/caz_annot_ft_bacteria_95_heatmap.qzv  \n",
      " extracting: data/07_Functional_analysis/data/cog_annot_ft_bacteria_95.qzv  \n",
      " extracting: data/07_Functional_analysis/data/cog_annot_ft_bacteria_95_heatmap.qzv  \n",
      " extracting: data/07_Functional_analysis/data/rgi_heatmap_bacteria_95.qzv  \n"
     ]
    }
   ],
   "source": [
    "# fetches useful files for the current notebook. All files will be saved in $data_dir\n",
    "!wget 'https://polybox.ethz.ch/index.php/s/WaSKZs2E5xn9SHm/download' -O data/Download.zip\n",
    "!unzip -o data/Download.zip -d data\n",
    "!rm data/Download.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c69fcd",
   "metadata": {},
   "source": [
    "### Step 1. Build sample/food mapping\n",
    "\n",
    "This step builds robust ID mappers from the dereplication table so that downstream plots can be labeled consistently.\n",
    "It creates helper functions such as `canon_id()`, `id_to_sample()`, and `id_to_food()` that are reused later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "317cca4b-beef-4828-95f5-a1ed438234ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# =========================\n",
    "# Build ID -> sample/food/category mappers from derep table\n",
    "# Works for:\n",
    "#   - member UUIDs (long uuid strings)\n",
    "#   - rep IDs (e.g., pb_m010, il_ms003-2)\n",
    "# =========================\n",
    "\n",
    "# ---- paths ----\n",
    "MAGS_TABLE_QZA = Path(\"data/07_Functional_analysis/data/mags_table_bacteria_95.qza\")\n",
    "META_TSV = Path(\"data/merged_metadata_filtered.tsv\")   # must contain sample_ID + fermented_food_type (and optionally category)\n",
    "\n",
    "EXPORT_DIR = Path(\"exported/mags_table_bacteria_95\")\n",
    "TSV = EXPORT_DIR / \"feature-table.tsv\"\n",
    "\n",
    "# ---- regex ----\n",
    "UUID_RE = re.compile(r\"[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\", re.I)\n",
    "\n",
    "def canon_id(s: str) -> str:\n",
    "    \"\"\"Extract UUID if present; otherwise lightly clean and lowercase.\"\"\"\n",
    "    s = str(s).strip()\n",
    "    m = UUID_RE.search(s)\n",
    "    if m:\n",
    "        return m.group(0).lower()\n",
    "    s = re.sub(r\"^MAG[_\\-]?\", \"\", s, flags=re.I)\n",
    "    return s.lower()\n",
    "\n",
    "def read_biom_tsv(tsv_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Read biom-converted TSV (skip first comment line, keep header).\"\"\"\n",
    "    df = pd.read_csv(tsv_path, sep=\"\\t\", skiprows=1)\n",
    "    first_col = df.columns[0]\n",
    "    df = df.set_index(first_col)\n",
    "    return df.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af897590",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: qiime tools export [OPTIONS]\n",
      "\n",
      "  Exporting extracts (and optionally transforms) data stored inside an\n",
      "  Artifact or Visualization. Note that Visualizations cannot be transformed\n",
      "  with --output-format\n",
      "\n",
      "Options:\n",
      "  --input-path ARTIFACT/VISUALIZATION\n",
      "                        Path to file that should be exported        [required]\n",
      "  --output-path PATH    Path to file or directory where data should be\n",
      "                        exported to                                 [required]\n",
      "  --output-format TEXT  Format which the data should be exported as. This\n",
      "                        option cannot be used with Visualizations\n",
      "  --help                Show this message and exit.\n",
      "\n",
      "                    There was a problem with the command:                     \n",
      " (1/1) Invalid value for '--input-path': File\n",
      "  'data/07_Functional_analysis/data/mags_table_bacteria_95.qza' does not\n",
      "  exist.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['qiime', 'tools', 'export', '--input-path', 'data/07_Functional_analysis/data/mags_table_bacteria_95.qza', '--output-path', 'exported/mags_table_bacteria_95']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m EXPORT_DIR\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m      3\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(EXPORT_DIR)\n\u001b[0;32m----> 5\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqiime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexport\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--input-path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMAGS_TABLE_QZA\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--output-path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mEXPORT_DIR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m subprocess\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m     10\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-i\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(EXPORT_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature-table.biom\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-o\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(TSV), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--to-tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     11\u001b[0m     check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m tab \u001b[38;5;241m=\u001b[39m read_biom_tsv(TSV)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:526\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    527\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['qiime', 'tools', 'export', '--input-path', 'data/07_Functional_analysis/data/mags_table_bacteria_95.qza', '--output-path', 'exported/mags_table_bacteria_95']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "# ---- export qza -> biom -> tsv ----\n",
    "if EXPORT_DIR.exists():\n",
    "    shutil.rmtree(EXPORT_DIR)\n",
    "\n",
    "subprocess.run(\n",
    "    [\"qiime\", \"tools\", \"export\", \"--input-path\", str(MAGS_TABLE_QZA), \"--output-path\", str(EXPORT_DIR)],\n",
    "    check=True\n",
    ")\n",
    "subprocess.run(\n",
    "    [\"biom\", \"convert\", \"-i\", str(EXPORT_DIR / \"feature-table.biom\"), \"-o\", str(TSV), \"--to-tsv\"],\n",
    "    check=True\n",
    ")\n",
    "\n",
    "tab = read_biom_tsv(TSV)\n",
    "\n",
    "# ---- normalize row/col ids ----\n",
    "tab.index = [canon_id(x) for x in tab.index]\n",
    "tab.columns = [canon_id(x) for x in tab.columns]\n",
    "\n",
    "# merge duplicates after normalization (no axis= warning)\n",
    "tab = tab.groupby(level=0).sum()\n",
    "tab = tab.T.groupby(level=0).sum().T\n",
    "\n",
    "# ---- orient table: rows=members, cols=reps ----\n",
    "row_sum = tab.sum(axis=1)\n",
    "rows_are_members = (row_sum.replace(0, np.nan).median() <= 1.5)\n",
    "if not rows_are_members:\n",
    "    tab = tab.T\n",
    "\n",
    "print(\"Interpreting mags_table as: rows=members, cols=reps. shape:\", tab.shape)\n",
    "\n",
    "# member -> rep\n",
    "member_to_rep = tab.idxmax(axis=1).to_dict()\n",
    "rep_ids = list(tab.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbe983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- read metadata ----\n",
    "meta = pd.read_csv(META_TSV, sep=\"\\t\", dtype=str)\n",
    "if \"sample_ID\" not in meta.columns:\n",
    "    raise ValueError(f\"'sample_ID' column not found in {META_TSV}. Columns: {meta.columns.tolist()}\")\n",
    "\n",
    "meta[\"sample_ID\"] = meta[\"sample_ID\"].astype(str)\n",
    "\n",
    "# required/optional metadata columns\n",
    "FOOD_COL = \"fermented_food_type\"\n",
    "CAT_COL  = \"category\"\n",
    "\n",
    "sample2food = {}\n",
    "if FOOD_COL in meta.columns:\n",
    "    sample2food = meta.drop_duplicates(\"sample_ID\").set_index(\"sample_ID\")[FOOD_COL].to_dict()\n",
    "\n",
    "sample2cat = {}\n",
    "if CAT_COL in meta.columns:\n",
    "    sample2cat = meta.drop_duplicates(\"sample_ID\").set_index(\"sample_ID\")[CAT_COL].to_dict()\n",
    "\n",
    "# build robust parser: rep_id -> sample_ID using known sample IDs from metadata\n",
    "sample_ids = meta[\"sample_ID\"].dropna().astype(str).unique().tolist()\n",
    "sid_lower_to_orig = {s.lower(): s for s in sample_ids}\n",
    "sid_pattern = re.compile(\"|\".join(sorted((re.escape(k) for k in sid_lower_to_orig.keys()), key=len, reverse=True))) if sample_ids else None\n",
    "\n",
    "def rep_to_sample(rep_id: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Parse sample_ID from rep IDs like:\n",
    "      pb_m010 -> M010\n",
    "      il_ms003-2 -> MS003-2\n",
    "      pb_a001 -> A001\n",
    "    \"\"\"\n",
    "    r = str(rep_id).lower().strip()\n",
    "    r = re.sub(r\"^(il|pb)_\", \"\", r)  # drop tech prefix\n",
    "    if sid_pattern is None:\n",
    "        return None\n",
    "    m = sid_pattern.search(r)\n",
    "    return sid_lower_to_orig[m.group(0)] if m else None\n",
    "\n",
    "rep_to_sample_map = {rep: rep_to_sample(rep) for rep in rep_ids}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8a33f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- lookup functions ----\n",
    "def id_to_sample(any_id: str) -> str:\n",
    "    k = canon_id(any_id)\n",
    "    rep = member_to_rep.get(k, k)   # member UUID -> rep; rep stays rep\n",
    "    s = rep_to_sample_map.get(rep)\n",
    "    return s if s else \"NA\"\n",
    "\n",
    "def id_to_food(any_id: str) -> str:\n",
    "    s = id_to_sample(any_id)\n",
    "    return str(sample2food.get(s, \"NA\")) if s != \"NA\" else \"NA\"\n",
    "\n",
    "def id_to_category(any_id: str) -> str:\n",
    "    s = id_to_sample(any_id)\n",
    "    return str(sample2cat.get(s, \"NA\")) if s != \"NA\" else \"NA\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a15d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- quick sanity check ----\n",
    "test_ids = list(tab.index[:5]) + list(tab.columns[:5])\n",
    "print(\"Sanity check:\")\n",
    "for t in test_ids:\n",
    "    print(t, \"->\", id_to_sample(t), \"|\", id_to_food(t), \"|\", id_to_category(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5082280",
   "metadata": {},
   "source": [
    "### Step 2. Export CAZ annotation feature table\n",
    "\n",
    "Exports the CAZ annotation feature table from QIIME2 (`.qza`) to TSV and defines helper functions for parsing and sample ID extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5927250f-0bd7-4442-bc0a-3024a12ebec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, shutil\n",
    "\n",
    "TSV = Path(\"exported/caz_ft/feature-table.tsv\")\n",
    "EXPORT_DIR = Path(\"exported/caz_ft\")\n",
    "QZA = Path(\"data/07_Functional_analysis/data/caz_annot_ft_bacteria_95.qza\")\n",
    "\n",
    "if not TSV.exists():\n",
    "    if EXPORT_DIR.exists():\n",
    "        shutil.rmtree(EXPORT_DIR)\n",
    "\n",
    "    subprocess.run([\n",
    "        \"qiime\",\"tools\",\"export\",\n",
    "        \"--input-path\", str(QZA),\n",
    "        \"--output-path\", str(EXPORT_DIR)\n",
    "    ], check=True)\n",
    "\n",
    "    subprocess.run([\n",
    "        \"biom\",\"convert\",\n",
    "        \"-i\", str(EXPORT_DIR/\"feature-table.biom\"),\n",
    "        \"-o\", str(TSV),\n",
    "        \"--to-tsv\"\n",
    "    ], check=True)\n",
    "\n",
    "print(\"Using TSV:\", TSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179ed8ac",
   "metadata": {},
   "source": [
    "### Step 3. CAZyme class composition\n",
    "\n",
    "**Figure: stacked bar chart of CAZyme class composition (Top N samples).**\n",
    "\n",
    "- **What it is:** Each bar is one sample (labels come from the ID→sample/food mappers in Step 1). The colored segments are CAZy *classes* (e.g., **GH**, **GT**, **CE**, **PL**, **AA**, **CBM**).\n",
    "- **What it shows:** How the functional *class-level* CAZyme profile differs between samples. If you plot **proportions**, bars sum to 1; if you plot **counts**, taller bars indicate higher total CAZyme signal.\n",
    "- **How to read it:** Look for (i) samples dominated by a single class, (ii) class shifts between foods/categories, and (iii) unusually high/low totals (the number above each bar, if enabled).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63479a6c-0f09-4189-9b87-f983a85a1d58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CAZyme class composition (label by sample/food via mags_table mapping)\n",
    "# Requires existing in notebook (from the successful mapping cell):\n",
    "#   - id_to_sample(any_id)\n",
    "#   - id_to_food(any_id)\n",
    "#   - canon_id(any_id)   (if not, we re-define a compatible one below)\n",
    "# =========================\n",
    "\n",
    "from pathlib import Path\n",
    "import subprocess, shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# ---------- sanity: mapping functions must exist ----------\n",
    "if \"id_to_sample\" not in globals() or \"id_to_food\" not in globals():\n",
    "    raise RuntimeError(\"Please run the mags_table -> id_to_sample/id_to_food mapping cell first (Sanity check must pass).\")\n",
    "\n",
    "# ---------- config ----------\n",
    "QZA = Path(\"data/07_Functional_analysis/data/caz_annot_ft_bacteria_95.qza\")\n",
    "EXPORT_DIR = Path(\"exported/caz_ft\")\n",
    "TSV = EXPORT_DIR / \"feature-table.tsv\"\n",
    "OUT_DIR = Path(\"figures\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "N = 20\n",
    "DO_EXPORT = False  # Set False if TSV already exists (from qiime export / biom convert); set True to re-export automatically\n",
    "\n",
    "# eukaryota MAG UUIDs to exclude (raw UUIDs)\n",
    "EXCLUDE_UUIDS = {\n",
    "    \"09ebb84d-e6d1-4c36-871b-45bee0ad115d\",\n",
    "    \"0c0b33fc-4ed2-4d06-b60c-4a5855e0e58b\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78253780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------- helpers ----------\n",
    "UUID_RE = re.compile(r\"[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\", re.I)\n",
    "\n",
    "# If canon_id is already defined in the mapping cell, reuse it; otherwise define a compatible version\n",
    "if \"canon_id\" not in globals():\n",
    "    def canon_id(s: str) -> str:\n",
    "        s = str(s).strip()\n",
    "        m = UUID_RE.search(s)\n",
    "        if m:\n",
    "            return m.group(0).lower()\n",
    "        s = re.sub(r\"^MAG[_\\-]?\", \"\", s, flags=re.I)\n",
    "        return s.lower()\n",
    "\n",
    "def cazy_class(feature_id: str) -> str:\n",
    "    m = re.match(r\"^(GH|GT|CE|PL|AA|CBM)\\d+\", str(feature_id).strip(), flags=re.I)\n",
    "    return m.group(1).upper() if m else \"Other\"\n",
    "\n",
    "def read_biom_tsv(tsv_path: Path) -> pd.DataFrame:\n",
    "    # biom convert output: row 1 is a comment, row 2 is the header\n",
    "    df = pd.read_csv(tsv_path, sep=\"\\t\", skiprows=1)\n",
    "    first_col = df.columns[0]  # '#OTU ID' or similar\n",
    "    return df.set_index(first_col)\n",
    "\n",
    "def stacked_bar(plot_df, title, ylabel, totals=None, out_prefix=\"plot\", is_prop=False):\n",
    "    order = [c for c in [\"GH\",\"GT\",\"CE\",\"PL\",\"AA\",\"CBM\",\"Other\"] if c in plot_df.columns]\n",
    "    x = np.arange(plot_df.shape[0])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(22, 8))\n",
    "    bottom = np.zeros(plot_df.shape[0])\n",
    "\n",
    "    for cls in order:\n",
    "        vals = plot_df[cls].values\n",
    "        ax.bar(x, vals, bottom=bottom, label=cls)\n",
    "        bottom += vals\n",
    "\n",
    "    # totals annotation\n",
    "    if totals is not None:\n",
    "        if is_prop:\n",
    "            y_text = 1.03\n",
    "            for i, lab in enumerate(plot_df.index):\n",
    "                ax.text(i, y_text, f\"{int(totals.loc[lab])}\",\n",
    "                        ha=\"center\", va=\"bottom\", fontsize=8, rotation=0)\n",
    "        else:\n",
    "            ypad = 0.01 * (bottom.max() if bottom.max() > 0 else 1)\n",
    "            for i, lab in enumerate(plot_df.index):\n",
    "                ax.text(i, bottom[i] + ypad, f\"{int(totals.loc[lab])}\",\n",
    "                        ha=\"center\", va=\"bottom\", fontsize=8, rotation=0)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(plot_df.index, rotation=60, ha=\"right\", fontsize=7)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.legend(ncols=7, bbox_to_anchor=(0.5, 1.22), loc=\"upper center\")\n",
    "\n",
    "    if is_prop:\n",
    "        ax.set_ylim(0, 1.18)\n",
    "    fig.subplots_adjust(bottom=0.40, top=0.78)\n",
    "\n",
    "    pdf = OUT_DIR / f\"{out_prefix}.pdf\"\n",
    "    svg = OUT_DIR / f\"{out_prefix}.svg\"\n",
    "    fig.savefig(pdf, dpi=300)\n",
    "    fig.savefig(svg)\n",
    "    plt.show()\n",
    "    print(\"Saved:\", pdf)\n",
    "    print(\"Saved:\", svg)\n",
    "\n",
    "def make_label(sample_id: str) -> str:\n",
    "    \"\"\"\n",
    "    sample_id may be:\n",
    "      - member UUID\n",
    "      - rep id (pb_m010 / il_ms003-2 ...)\n",
    "    We consistently map via id_to_sample / id_to_food\n",
    "    \"\"\"\n",
    "    sid = str(sample_id)\n",
    "    short = canon_id(sid)\n",
    "    # If it is a UUID, use the first 8 chars; otherwise keep the original string (more readable)\n",
    "    if UUID_RE.search(sid):\n",
    "        short = short[:8]\n",
    "    else:\n",
    "        short = sid\n",
    "    return f\"{id_to_sample(sid)} | {id_to_food(sid)} | {short}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d42383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------- export qza -> biom -> tsv (optional) ----------\n",
    "if DO_EXPORT:\n",
    "    if EXPORT_DIR.exists():\n",
    "        shutil.rmtree(EXPORT_DIR)\n",
    "    subprocess.run([\n",
    "        \"qiime\", \"tools\", \"export\",\n",
    "        \"--input-path\", str(QZA),\n",
    "        \"--output-path\", str(EXPORT_DIR)\n",
    "    ], check=True)\n",
    "\n",
    "    subprocess.run([\n",
    "        \"biom\", \"convert\",\n",
    "        \"-i\", str(EXPORT_DIR / \"feature-table.biom\"),\n",
    "        \"-o\", str(TSV),\n",
    "        \"--to-tsv\"\n",
    "    ], check=True)\n",
    "\n",
    "# ---------- read matrix (features x sampleIDs) ----------\n",
    "df = read_biom_tsv(TSV)\n",
    "mat = df.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Normalize column names (more robust for dropping/merging)\n",
    "mat.columns = [canon_id(c) if UUID_RE.search(str(c)) else str(c).strip() for c in mat.columns]\n",
    "# Merge any duplicate columns (avoid axis= to prevent pandas FutureWarning)\n",
    "mat = mat.T.groupby(level=0).sum().T\n",
    "\n",
    "# ---------- exclude eukaryota IDs ----------\n",
    "exclude_keys = {canon_id(u) for u in EXCLUDE_UUIDS}\n",
    "# Optional: if member_to_rep exists (from the mapping cell), also drop the corresponding rep IDs for safety\n",
    "rep_exclude = set()\n",
    "if \"member_to_rep\" in globals():\n",
    "    for u in EXCLUDE_UUIDS:\n",
    "        k = canon_id(u)\n",
    "        if k in member_to_rep:\n",
    "            rep_exclude.add(member_to_rep[k])\n",
    "\n",
    "cols_before = set(mat.columns)\n",
    "mat = mat.drop(columns=[c for c in mat.columns if (c in exclude_keys) or (c in rep_exclude)], errors=\"ignore\")\n",
    "print(\"Excluded:\", sorted((cols_before - set(mat.columns))))\n",
    "\n",
    "print(\"Matrix shape (features x sampleIDs):\", mat.shape)\n",
    "print(\"Example columns:\", list(mat.columns[:5]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e4882d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------- sum into CAZyme classes ----------\n",
    "classes = pd.Series(mat.index, index=mat.index).map(cazy_class)\n",
    "class_sum = mat.groupby(classes).sum()  # class x sampleID\n",
    "\n",
    "# keep standard order\n",
    "order = [c for c in [\"GH\",\"GT\",\"CE\",\"PL\",\"AA\",\"CBM\",\"Other\"] if c in class_sum.index]\n",
    "class_sum = class_sum.loc[order]\n",
    "\n",
    "totals_all = class_sum.sum(axis=0)\n",
    "\n",
    "# ---------- top N ----------\n",
    "top_ids = totals_all.sort_values(ascending=False).head(N).index\n",
    "top_totals_raw = totals_all.loc[top_ids]\n",
    "\n",
    "top_counts = class_sum[top_ids].T  # sampleID x class\n",
    "top_prop = (class_sum[top_ids] / top_totals_raw.replace(0, np.nan)).T.fillna(0)\n",
    "\n",
    "# ---------- relabel for plotting ----------\n",
    "labels = [make_label(x) for x in top_ids]\n",
    "\n",
    "top_counts.index = labels\n",
    "top_prop.index = labels\n",
    "\n",
    "top_totals = top_totals_raw.copy()\n",
    "top_totals.index = labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8acc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------- plot ----------\n",
    "stacked_bar(\n",
    "    plot_df=top_prop,\n",
    "    title=f\"CAZyme class composition (Top {N}) — totals annotated\",\n",
    "    ylabel=\"Proportion of CAZyme classes\",\n",
    "    totals=top_totals,\n",
    "    out_prefix=f\"cazy_class_top{N}_prop_annot_labeled\",\n",
    "    is_prop=True\n",
    ")\n",
    "\n",
    "stacked_bar(\n",
    "    plot_df=top_counts,\n",
    "    title=f\"CAZyme class composition (Top {N}) — absolute counts\",\n",
    "    ylabel=\"CAZyme class counts\",\n",
    "    totals=None,\n",
    "    out_prefix=f\"cazy_class_top{N}_counts_labeled\",\n",
    "    is_prop=False\n",
    ")\n",
    "\n",
    "# ---------- top list table ----------\n",
    "top_list = pd.DataFrame({\n",
    "    \"id\": list(top_ids),\n",
    "    \"sample_ID\": [id_to_sample(x) for x in top_ids],\n",
    "    \"food\": [id_to_food(x) for x in top_ids],\n",
    "    \"cazy_total\": top_totals_raw.values\n",
    "}).sort_values(\"cazy_total\", ascending=False)\n",
    "\n",
    "display(top_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fe24c7",
   "metadata": {},
   "source": [
    "### Step 4. CAZy family PCA\n",
    "\n",
    "**Figures: PCA scatter plots of CAZy *family*-level profiles (Top-N and/or All families).**\n",
    "\n",
    "- **What it is:** A dimensionality reduction of the per-sample CAZy family abundance matrix. Each point is a sample; points are colored by food (or other grouping).\n",
    "- **What it shows:** Samples that cluster together have **similar CAZy family repertoires** after normalization (log1p + z-score per feature).\n",
    "- **How to read it:** Check whether samples separate by food/category along PC1/PC2 (the axis labels include explained variance). If a zoom/outlier report is enabled, you can identify samples driving separation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc407e0-3d09-4342-bfde-bdbb2c7b9c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# =========================\n",
    "# CAZy family PCA (TopN + All)\n",
    "# - excludes known euk IDs\n",
    "# - labels/colored by food via id_to_food()\n",
    "# - outputs:\n",
    "#     figures/cazy_pca_topN_labeled.png\n",
    "#     figures/cazy_pca_all_full.png\n",
    "#     figures/cazy_pca_all_zoom.png\n",
    "#     figures/cazy_pca_all_outliers.tsv\n",
    "# =========================\n",
    "\n",
    "# ---- require mapping fns exist ----\n",
    "if \"id_to_sample\" not in globals() or \"id_to_food\" not in globals():\n",
    "    raise RuntimeError(\"Please run the mags_table mapping cell first (id_to_sample/id_to_food).\")\n",
    "\n",
    "OUT_DIR = Path(\"figures\")\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "UUID_RE = re.compile(r\"[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\", re.I)\n",
    "\n",
    "# If canon_id already exists (from mapping cell), keep it; otherwise define one.\n",
    "if \"canon_id\" not in globals():\n",
    "    def canon_id(s: str) -> str:\n",
    "        s = str(s).strip()\n",
    "        m = UUID_RE.search(s)\n",
    "        if m:\n",
    "            return m.group(0).lower()\n",
    "        s = re.sub(r\"^MAG[_\\-]?\", \"\", s, flags=re.I)\n",
    "        return s.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20eae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- eukaryota UUIDs to exclude ----\n",
    "EXCLUDE_UUIDS = {\n",
    "    \"09ebb84d-e6d1-4c36-871b-45bee0ad115d\",\n",
    "    \"0c0b33fc-4ed2-4d06-b60c-4a5855e0e58b\",\n",
    "}\n",
    "EXCLUDE_KEYS = {canon_id(x) for x in EXCLUDE_UUIDS}\n",
    "\n",
    "def drop_excluded_columns(mat_fxS: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Drop excluded UUID cols; if member_to_rep exists, drop corresponding reps too.\"\"\"\n",
    "    cols = list(mat_fxS.columns)\n",
    "\n",
    "    # drop direct UUID columns\n",
    "    to_drop = set(c for c in cols if c in EXCLUDE_KEYS)\n",
    "\n",
    "    # if member_to_rep exists, also drop their reps (extra safety)\n",
    "    if \"member_to_rep\" in globals():\n",
    "        for u in EXCLUDE_KEYS:\n",
    "            rep = member_to_rep.get(u)\n",
    "            if rep is not None and rep in cols:\n",
    "                to_drop.add(rep)\n",
    "\n",
    "    if to_drop:\n",
    "        print(\"Excluding columns:\", sorted(to_drop))\n",
    "        return mat_fxS.drop(columns=list(to_drop), errors=\"ignore\")\n",
    "    return mat_fxS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf793a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pca_2d(X: np.ndarray):\n",
    "    \"\"\"Simple PCA via SVD. Returns (scores2d, explained_variance_ratio[2]).\"\"\"\n",
    "    Xc = X - X.mean(axis=0, keepdims=True)\n",
    "    U, S, Vt = np.linalg.svd(Xc, full_matrices=False)\n",
    "    scores = U[:, :2] * S[:2]\n",
    "    var = (S**2) / (X.shape[0] - 1)\n",
    "    evr = var / var.sum()\n",
    "    return scores, evr[:2]\n",
    "\n",
    "def make_pca_plot(mat_features_x_samples: pd.DataFrame,\n",
    "                  title: str,\n",
    "                  outpath: Path,\n",
    "                  color_by: str = \"food\",\n",
    "                  show_legend_max_groups: int = 15,\n",
    "                  zoom_quantile: tuple[float, float] | None = None,\n",
    "                  outlier_report_path: Path | None = None):\n",
    "    \"\"\"\n",
    "    mat_features_x_samples: features x samples (counts)\n",
    "\n",
    "    zoom_quantile:\n",
    "      None -> full view\n",
    "      (0.01, 0.99) -> zoom to 1%~99% quantiles for both axes\n",
    "\n",
    "    outlier_report_path:\n",
    "      if provided and zoom_quantile is not None, writes a TSV listing outliers.\n",
    "    \"\"\"\n",
    "    # samples x features\n",
    "    X = mat_features_x_samples.T.copy()\n",
    "\n",
    "    # log reduce skew\n",
    "    X = np.log1p(X)\n",
    "\n",
    "    # z-score per feature\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0).replace(0, 1)\n",
    "\n",
    "    scores, evr2 = pca_2d(X.values)\n",
    "    pc1, pc2 = scores[:, 0], scores[:, 1]\n",
    "\n",
    "    # group labels\n",
    "    if color_by == \"food\":\n",
    "        groups = pd.Series([id_to_food(s) for s in X.index], index=X.index)\n",
    "        group_name = \"Food\"\n",
    "    elif color_by == \"sample\":\n",
    "        groups = pd.Series([id_to_sample(s) for s in X.index], index=X.index)\n",
    "        group_name = \"Sample\"\n",
    "    else:\n",
    "        groups = pd.Series([\"All\"] * len(X.index), index=X.index)\n",
    "        group_name = \"Group\"\n",
    "\n",
    "    # zoom limits + outliers\n",
    "    outlier_mask = np.zeros(len(X.index), dtype=bool)\n",
    "    xlim = ylim = None\n",
    "    if zoom_quantile is not None:\n",
    "        lo, hi = zoom_quantile\n",
    "        x1, x2 = np.quantile(pc1, [lo, hi])\n",
    "        y1, y2 = np.quantile(pc2, [lo, hi])\n",
    "        xpad = 0.05 * (x2 - x1 if x2 > x1 else 1)\n",
    "        ypad = 0.05 * (y2 - y1 if y2 > y1 else 1)\n",
    "        xlim = (x1 - xpad, x2 + xpad)\n",
    "        ylim = (y1 - ypad, y2 + ypad)\n",
    "        outlier_mask = (pc1 < xlim[0]) | (pc1 > xlim[1]) | (pc2 < ylim[0]) | (pc2 > ylim[1])\n",
    "\n",
    "        if outlier_report_path is not None:\n",
    "            out_df = pd.DataFrame({\n",
    "                \"id\": list(X.index),\n",
    "                \"sample_ID\": [id_to_sample(i) for i in X.index],\n",
    "                \"food\": [id_to_food(i) for i in X.index],\n",
    "                \"PC1\": pc1,\n",
    "                \"PC2\": pc2,\n",
    "                \"is_outlier\": outlier_mask\n",
    "            }).sort_values([\"is_outlier\", \"PC1\"], ascending=[False, True])\n",
    "            out_df.to_csv(outlier_report_path, sep=\"\\t\", index=False)\n",
    "            print(\"Saved outlier report:\", outlier_report_path)\n",
    "            print(\"Outliers (head):\")\n",
    "            display(out_df[out_df[\"is_outlier\"]].head(10))\n",
    "\n",
    "    # Plot PCA scores (PC1 vs PC2), colored by the selected grouping variable\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    uniq = groups.unique().tolist()\n",
    "    show_legend = len(uniq) <= show_legend_max_groups\n",
    "\n",
    "    for g in uniq:\n",
    "        mask = (groups == g).values\n",
    "        plt.scatter(pc1[mask], pc2[mask], alpha=0.75, s=25, label=g if show_legend else None)\n",
    "\n",
    "    if xlim is not None:\n",
    "        plt.xlim(*xlim)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "\n",
    "    plt.xlabel(f\"PC1 ({evr2[0]*100:.1f}%)\")\n",
    "    plt.ylabel(f\"PC2 ({evr2[1]*100:.1f}%)\")\n",
    "    plt.title(title)\n",
    "\n",
    "    if show_legend:\n",
    "        plt.legend(title=group_name, bbox_to_anchor=(1.02, 1), loc=\"upper left\", fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=300)\n",
    "    plt.show()\n",
    "    print(\"Saved:\", outpath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e2582",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Prepare matrix for PCA\n",
    "# =========================\n",
    "\n",
    "# Ensure column IDs consistent + merge duplicates\n",
    "mat_pca = mat.copy()\n",
    "mat_pca.columns = [canon_id(c) if UUID_RE.search(str(c)) else str(c).strip() for c in mat_pca.columns]\n",
    "mat_pca = mat_pca.T.groupby(level=0).sum().T\n",
    "\n",
    "# Exclude euks\n",
    "mat_pca = drop_excluded_columns(mat_pca)\n",
    "\n",
    "# TopN selection by total counts across CAZy families\n",
    "N = 20\n",
    "totals = mat_pca.sum(axis=0)\n",
    "top_ids = totals.sort_values(ascending=False).head(N).index\n",
    "\n",
    "# =========================\n",
    "# Plots\n",
    "# =========================\n",
    "\n",
    "# 1) TopN PCA\n",
    "make_pca_plot(\n",
    "    mat_pca[top_ids],\n",
    "    title=f\"CAZy family PCA (Top {len(top_ids)})\",\n",
    "    outpath=OUT_DIR / \"cazy_pca_topN_labeled.png\",\n",
    "    color_by=\"food\"\n",
    ")\n",
    "\n",
    "# 2) All samples PCA (full view)\n",
    "make_pca_plot(\n",
    "    mat_pca,\n",
    "    title=\"CAZy family PCA (All samples) — full\",\n",
    "    outpath=OUT_DIR / \"cazy_pca_all_full.png\",\n",
    "    color_by=\"food\",\n",
    "    zoom_quantile=None\n",
    ")\n",
    "\n",
    "# 3) All samples PCA (zoom view) + outlier report\n",
    "make_pca_plot(\n",
    "    mat_pca,\n",
    "    title=\"CAZy family PCA (All samples) — zoom (1–99%)\",\n",
    "    outpath=OUT_DIR / \"cazy_pca_all_zoom.png\",\n",
    "    color_by=\"food\",\n",
    "    zoom_quantile=(0.01, 0.99),\n",
    "    outlier_report_path=OUT_DIR / \"cazy_pca_all_outliers.tsv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09166c4",
   "metadata": {},
   "source": [
    "### Step 5. Top CAZy families dot plot\n",
    "\n",
    "**Figure: bubble (dot) plot of Top CAZy families across selected samples.**\n",
    "\n",
    "- **What it is:** A matrix-style visualization where **x = CAZy family**, **y = sample**. Each dot represents the abundance of a family in a sample.\n",
    "- **Encoding:**  \n",
    "  - **Dot size** scales with relative abundance (after a log transform + quantile scaling).  \n",
    "  - **Dot color** encodes the CAZy class (GH/GT/CE/PL/AA/CBM/Other), so you can see class structure at a glance.\n",
    "- **What it shows:** Which families are broadly shared versus sample-specific, and which foods/samples are enriched for particular family groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f27bb9-94e6-4d5e-abe9-012d739f23da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# ---------------------------\n",
    "# REQUIRE: mapping functions exist\n",
    "# ---------------------------\n",
    "if \"id_to_sample\" not in globals() or \"id_to_food\" not in globals():\n",
    "    raise RuntimeError(\"Please run the mags_table mapping cell first (id_to_sample/id_to_food).\")\n",
    "\n",
    "# ---------------------------\n",
    "# Params (edit as needed)\n",
    "# ---------------------------\n",
    "N_SAMPLES = 25   # Top samples/IDs\n",
    "N_FAMS = 30      # Top CAZy families\n",
    "OUT = Path(\"figures/cazy_topfamilies_dotplot_rel_discrete_labeled.png\")\n",
    "OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# eukaryota IDs to exclude\n",
    "EXCLUDE_UUIDS = {\n",
    "    \"09ebb84d-e6d1-4c36-871b-45bee0ad115d\",\n",
    "    \"0c0b33fc-4ed2-4d06-b60c-4a5855e0e58b\",\n",
    "}\n",
    "\n",
    "UUID_RE = re.compile(r\"[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\", re.I)\n",
    "\n",
    "# use existing canon_id if present; otherwise define compatible one\n",
    "if \"canon_id\" not in globals():\n",
    "    def canon_id(s: str) -> str:\n",
    "        s = str(s).strip()\n",
    "        m = UUID_RE.search(s)\n",
    "        if m:\n",
    "            return m.group(0).lower()\n",
    "        s = re.sub(r\"^MAG[_\\-]?\", \"\", s, flags=re.I)\n",
    "        return s.lower()\n",
    "\n",
    "EXCLUDE_KEYS = {canon_id(x) for x in EXCLUDE_UUIDS}\n",
    "\n",
    "def drop_excluded_columns(mat_fxS: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Drop excluded UUID cols; if member_to_rep exists, also drop corresponding reps.\"\"\"\n",
    "    cols = list(mat_fxS.columns)\n",
    "    to_drop = set(c for c in cols if c in EXCLUDE_KEYS)\n",
    "\n",
    "    if \"member_to_rep\" in globals():\n",
    "        for u in EXCLUDE_KEYS:\n",
    "            rep = member_to_rep.get(u)\n",
    "            if rep is not None and rep in cols:\n",
    "                to_drop.add(rep)\n",
    "\n",
    "    if to_drop:\n",
    "        print(\"Excluding columns:\", sorted(to_drop))\n",
    "        return mat_fxS.drop(columns=list(to_drop), errors=\"ignore\")\n",
    "    return mat_fxS\n",
    "\n",
    "def cazy_class(fam: str) -> str:\n",
    "    m = re.match(r\"^(GH|GT|CE|PL|AA|CBM)\\d+\", str(fam).strip(), flags=re.I)\n",
    "    return m.group(1).upper() if m else \"Other\"\n",
    "\n",
    "def make_id_label(x: str, short_uuid: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Y-axis label: sample_ID | food | short-id\n",
    "    - If a UUID: use the first 8 characters as short-id\n",
    "    - If not a UUID: use the original id as short-id (e.g., pb_m010)\n",
    "    \"\"\"\n",
    "    x = str(x)\n",
    "    samp = id_to_sample(x)\n",
    "    food = id_to_food(x)\n",
    "    if short_uuid and UUID_RE.search(x):\n",
    "        sid = canon_id(x)[:8]\n",
    "    else:\n",
    "        sid = x\n",
    "    return f\"{samp} | {food} | {sid}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c2354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# prepare matrix: normalize columns + merge duplicates + drop euks\n",
    "# ---------------------------\n",
    "mat2 = mat.copy()\n",
    "\n",
    "# Normalize column names (UUID -> canonical; non-UUID -> strip/lower via canon_id)\n",
    "mat2.columns = [canon_id(c) if UUID_RE.search(str(c)) else canon_id(str(c)) for c in mat2.columns]\n",
    "\n",
    "# Merge duplicate columns (avoid axis= FutureWarning)\n",
    "mat2 = mat2.T.groupby(level=0).sum().T\n",
    "\n",
    "# Exclude eukaryote IDs\n",
    "mat2 = drop_excluded_columns(mat2)\n",
    "\n",
    "# ---------------------------\n",
    "# choose top samples/families\n",
    "# ---------------------------\n",
    "sample_totals = mat2.sum(axis=0).sort_values(ascending=False)\n",
    "top_samples = sample_totals.head(N_SAMPLES).index\n",
    "\n",
    "fam_totals = mat2[top_samples].sum(axis=1).sort_values(ascending=False)\n",
    "top_fams = fam_totals.head(N_FAMS).index\n",
    "\n",
    "sub = mat2.loc[top_fams, top_samples]  # fam x sample (counts)\n",
    "\n",
    "# ---------------------------\n",
    "# convert to relative abundance within each sample\n",
    "# ---------------------------\n",
    "sub_rel = sub.div(sub.sum(axis=0).replace(0, np.nan), axis=1).fillna(0)  # fam x sample\n",
    "\n",
    "# long table: family, id, rel\n",
    "long = sub_rel.stack().reset_index(name=\"rel\")\n",
    "long.columns = [\"family\", \"id\", \"rel\"]\n",
    "long = long[long[\"rel\"] > 0].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282f86ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# size and color (discrete by class)\n",
    "# ---------------------------\n",
    "long[\"class\"] = long[\"family\"].map(cazy_class)\n",
    "\n",
    "# dot size: log10(CPM+1) then quantile-scale\n",
    "long[\"size_raw\"] = np.log10(long[\"rel\"] * 1e6 + 1)\n",
    "\n",
    "v = long[\"size_raw\"].values\n",
    "v_lo, v_hi = np.quantile(v, [0.01, 0.99])\n",
    "v_scaled = (v - v_lo) / (v_hi - v_lo + 1e-12)\n",
    "v_scaled = np.clip(v_scaled, 0, 1)\n",
    "s_min, s_max = 15, 250\n",
    "long[\"size\"] = s_min + v_scaled * (s_max - s_min)\n",
    "\n",
    "# axis order\n",
    "id_order = list(top_samples)     # y: sample IDs (top totals)\n",
    "fam_order = list(top_fams)       # x: top families\n",
    "id_to_y = {u:i for i,u in enumerate(id_order)}\n",
    "fam_to_x = {f:i for i,f in enumerate(fam_order)}\n",
    "long[\"x\"] = long[\"family\"].map(fam_to_x)\n",
    "long[\"y\"] = long[\"id\"].map(id_to_y)\n",
    "\n",
    "# fixed class colors (tab10)\n",
    "tab10 = plt.get_cmap(\"tab10\")\n",
    "class_colors = {\n",
    "    \"GH\": tab10(0),\n",
    "    \"GT\": tab10(1),\n",
    "    \"CE\": tab10(2),\n",
    "    \"PL\": tab10(3),\n",
    "    \"AA\": tab10(4),\n",
    "    \"CBM\": tab10(5),\n",
    "    \"Other\": tab10(7),\n",
    "}\n",
    "point_colors = long[\"class\"].apply(lambda x: class_colors.get(x, class_colors[\"Other\"])).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4791df3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Bubble plot: Top CAZy families (x) vs samples (y); size ~ relative abundance, color ~ CAZy class\n",
    "# ---------------------------\n",
    "fig_w = max(10, N_FAMS * 0.35)\n",
    "fig_h = max(6, N_SAMPLES * 0.28)\n",
    "plt.figure(figsize=(fig_w, fig_h))\n",
    "\n",
    "plt.scatter(\n",
    "    long[\"x\"], long[\"y\"],\n",
    "    s=long[\"size\"].values,\n",
    "    c=point_colors,\n",
    "    alpha=0.85,\n",
    "    edgecolors=\"none\"\n",
    ")\n",
    "\n",
    "plt.xticks(range(len(fam_order)), fam_order, rotation=90)\n",
    "\n",
    "# Y-axis label: use sample | food | short-id (more readable)\n",
    "y_labels = [make_id_label(u, short_uuid=True) for u in id_order]\n",
    "plt.yticks(range(len(id_order)), y_labels)\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"CAZy family (top)\")\n",
    "plt.ylabel(\"Top samples/IDs (labeled)\")\n",
    "plt.title(\n",
    "    f\"CAZy top families dotplot (Top {N_SAMPLES} samples × Top {N_FAMS} families)\\n\"\n",
    "    f\"dot size ~ scaled log10(CPM+1), color ~ CAZy class\"\n",
    ")\n",
    "\n",
    "# legend for classes\n",
    "handles = [\n",
    "    Line2D([0], [0], marker=\"o\", linestyle=\"\", label=cls,\n",
    "           markerfacecolor=class_colors[cls], markeredgecolor=\"none\", markersize=8)\n",
    "    for cls in [\"GH\",\"GT\",\"CE\",\"PL\",\"AA\",\"CBM\",\"Other\"]\n",
    "]\n",
    "plt.legend(handles=handles, title=\"CAZy class\", bbox_to_anchor=(1.01, 1), loc=\"upper left\", borderaxespad=0.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT, dpi=300)\n",
    "plt.show()\n",
    "print(\"Saved:\", OUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c0b56",
   "metadata": {},
   "source": [
    "### Step 6. COG functional composition\n",
    "\n",
    "**Figures: COG category composition (stacked bars) + PCA (optional).**\n",
    "\n",
    "- **Stacked bar chart (Top N samples):**  \n",
    "  - **What it is:** Each bar is one sample; segments are COG categories.  \n",
    "  - **What it shows:** Relative functional allocation across categories, making it easy to compare category shifts between samples/foods.\n",
    "- **PCA plot (all samples):**  \n",
    "  - **What it is:** PCA on the per-sample COG-category profile (after normalization).  \n",
    "  - **What it shows:** Whether samples cluster by food/category based on higher-level functional composition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae62b3c-ea06-4e78-8bc7-45cff61440d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# =========================\n",
    "# Require mapping fns\n",
    "# =========================\n",
    "if \"id_to_sample\" not in globals() or \"id_to_food\" not in globals():\n",
    "    raise RuntimeError(\"Please run the mags_table mapping cell first (id_to_sample/id_to_food).\")\n",
    "\n",
    "# =========================\n",
    "# Paths / params\n",
    "# =========================\n",
    "DATA_DIR = Path(\"data/07_Functional_analysis/data\")\n",
    "COG_QZA = DATA_DIR / \"cog_annot_ft_bacteria_95.qza\"\n",
    "\n",
    "OUT_DIR = Path(\"figures\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "EXPORT_DIR = Path(\"exported/cog_ft\")\n",
    "TSV = EXPORT_DIR / \"feature-table.tsv\"\n",
    "\n",
    "N_UUID = 25  # top samples in stacked bar\n",
    "\n",
    "# euk UUIDs to exclude\n",
    "EXCLUDE_UUIDS = {\n",
    "    \"09ebb84d-e6d1-4c36-871b-45bee0ad115d\",\n",
    "    \"0c0b33fc-4ed2-4d06-b60c-4a5855e0e58b\",\n",
    "}\n",
    "\n",
    "UUID_RE = re.compile(r\"[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\", re.I)\n",
    "\n",
    "# use existing canon_id if present; otherwise define\n",
    "if \"canon_id\" not in globals():\n",
    "    def canon_id(s: str) -> str:\n",
    "        s = str(s).strip()\n",
    "        m = UUID_RE.search(s)\n",
    "        if m:\n",
    "            return m.group(0).lower()\n",
    "        s = re.sub(r\"^MAG[_\\-]?\", \"\", s, flags=re.I)\n",
    "        return s.lower()\n",
    "\n",
    "EXCLUDE_KEYS = {canon_id(x) for x in EXCLUDE_UUIDS}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984bae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Export qza -> tsv (only if needed)\n",
    "# =========================\n",
    "if not TSV.exists():\n",
    "    if EXPORT_DIR.exists():\n",
    "        shutil.rmtree(EXPORT_DIR)\n",
    "    EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    subprocess.run(\n",
    "        [\"qiime\", \"tools\", \"export\", \"--input-path\", str(COG_QZA), \"--output-path\", str(EXPORT_DIR)],\n",
    "        check=True\n",
    "    )\n",
    "    subprocess.run(\n",
    "        [\"biom\", \"convert\", \"-i\", str(EXPORT_DIR / \"feature-table.biom\"), \"-o\", str(TSV), \"--to-tsv\"],\n",
    "        check=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e9652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def read_biom_tsv(tsv_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    biom convert output:\n",
    "      line1: # Constructed from biom file\n",
    "      line2: #OTU ID <sample1> <sample2> ...\n",
    "    So: skip row 1 and use row 2 as the header\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(tsv_path, sep=\"\\t\", skiprows=1)\n",
    "    df = df.set_index(df.columns[0])\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "    return df  # features x sampleIDs\n",
    "\n",
    "def pca_2d(X: np.ndarray):\n",
    "    Xc = X - X.mean(axis=0, keepdims=True)\n",
    "    U, S, Vt = np.linalg.svd(Xc, full_matrices=False)\n",
    "    scores = U[:, :2] * S[:2]\n",
    "    var = (S**2) / (X.shape[0] - 1)\n",
    "    evr = var / var.sum()\n",
    "    return scores, evr[:2]\n",
    "\n",
    "def drop_excluded_columns(mat_fxS: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Drop excluded UUID cols; if member_to_rep exists, also drop corresponding reps.\"\"\"\n",
    "    cols = list(mat_fxS.columns)\n",
    "    to_drop = set(c for c in cols if c in EXCLUDE_KEYS)\n",
    "\n",
    "    if \"member_to_rep\" in globals():\n",
    "        for u in EXCLUDE_KEYS:\n",
    "            rep = member_to_rep.get(u)\n",
    "            if rep is not None and rep in cols:\n",
    "                to_drop.add(rep)\n",
    "\n",
    "    if to_drop:\n",
    "        print(\"Excluding columns:\", sorted(to_drop))\n",
    "        return mat_fxS.drop(columns=list(to_drop), errors=\"ignore\")\n",
    "    return mat_fxS\n",
    "\n",
    "def make_label(sid: str) -> str:\n",
    "    \"\"\"\n",
    "    sid can be UUID or rep id. Label as:\n",
    "      sample_ID | food | short\n",
    "    \"\"\"\n",
    "    sid = str(sid)\n",
    "    sample = id_to_sample(sid)\n",
    "    food = id_to_food(sid)\n",
    "    if UUID_RE.search(sid):\n",
    "        short = canon_id(sid)[:8]\n",
    "    else:\n",
    "        short = sid\n",
    "    return f\"{sample} | {food} | {short}\"\n",
    "\n",
    "def pca_plot(mat_features_x_samples: pd.DataFrame,\n",
    "             title: str,\n",
    "             outpath: Path,\n",
    "             color_by: str = \"food\",\n",
    "             zoom_quantile: tuple[float, float] | None = None,\n",
    "             outlier_report_path: Path | None = None,\n",
    "             legend_max_groups: int = 15):\n",
    "\n",
    "    X = mat_features_x_samples.T.copy()  # samples x features\n",
    "    X = np.log1p(X)\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0).replace(0, 1)\n",
    "\n",
    "    scores, evr2 = pca_2d(X.values)\n",
    "    pc1, pc2 = scores[:, 0], scores[:, 1]\n",
    "\n",
    "    if color_by == \"food\":\n",
    "        groups = pd.Series([id_to_food(i) for i in X.index], index=X.index)\n",
    "        group_name = \"Food\"\n",
    "    elif color_by == \"sample\":\n",
    "        groups = pd.Series([id_to_sample(i) for i in X.index], index=X.index)\n",
    "        group_name = \"Sample\"\n",
    "    else:\n",
    "        groups = pd.Series([\"All\"] * len(X.index), index=X.index)\n",
    "        group_name = \"Group\"\n",
    "\n",
    "    xlim = ylim = None\n",
    "    outlier_mask = np.zeros(len(X.index), dtype=bool)\n",
    "    if zoom_quantile is not None:\n",
    "        lo, hi = zoom_quantile\n",
    "        x1, x2 = np.quantile(pc1, [lo, hi])\n",
    "        y1, y2 = np.quantile(pc2, [lo, hi])\n",
    "        xpad = 0.05 * (x2 - x1 if x2 > x1 else 1)\n",
    "        ypad = 0.05 * (y2 - y1 if y2 > y1 else 1)\n",
    "        xlim = (x1 - xpad, x2 + xpad)\n",
    "        ylim = (y1 - ypad, y2 + ypad)\n",
    "        outlier_mask = (pc1 < xlim[0]) | (pc1 > xlim[1]) | (pc2 < ylim[0]) | (pc2 > ylim[1])\n",
    "\n",
    "        if outlier_report_path is not None:\n",
    "            out_df = pd.DataFrame({\n",
    "                \"id\": list(X.index),\n",
    "                \"sample_ID\": [id_to_sample(i) for i in X.index],\n",
    "                \"food\": [id_to_food(i) for i in X.index],\n",
    "                \"PC1\": pc1,\n",
    "                \"PC2\": pc2,\n",
    "                \"is_outlier\": outlier_mask\n",
    "            }).sort_values([\"is_outlier\", \"PC1\"], ascending=[False, True])\n",
    "            out_df.to_csv(outlier_report_path, sep=\"\\t\", index=False)\n",
    "            print(\"Saved outlier report:\", outlier_report_path)\n",
    "            print(\"Outliers (top 10):\")\n",
    "            print(out_df[out_df[\"is_outlier\"]].head(10).to_string(index=False))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    uniq = groups.unique().tolist()\n",
    "    show_legend = len(uniq) <= legend_max_groups\n",
    "\n",
    "    for g in uniq:\n",
    "        m = (groups == g).values\n",
    "        plt.scatter(pc1[m], pc2[m], alpha=0.75, s=25, label=g if show_legend else None)\n",
    "\n",
    "    if xlim is not None:\n",
    "        plt.xlim(*xlim)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "\n",
    "    plt.xlabel(f\"PC1 ({evr2[0]*100:.1f}%)\")\n",
    "    plt.ylabel(f\"PC2 ({evr2[1]*100:.1f}%)\")\n",
    "    plt.title(title)\n",
    "\n",
    "    if show_legend:\n",
    "        plt.legend(title=group_name, bbox_to_anchor=(1.02, 1), loc=\"upper left\", fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=300)\n",
    "    plt.show()\n",
    "    print(\"Saved:\", outpath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a47006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Load + normalize + exclude\n",
    "# =========================\n",
    "cog_mat = read_biom_tsv(TSV)\n",
    "\n",
    "# normalize column IDs + merge duplicates\n",
    "cog_mat.columns = [canon_id(c) if UUID_RE.search(str(c)) else str(c).strip() for c in cog_mat.columns]\n",
    "cog_mat = cog_mat.T.groupby(level=0).sum().T\n",
    "\n",
    "# exclude euks\n",
    "cog_mat = drop_excluded_columns(cog_mat)\n",
    "\n",
    "print(\"COG matrix shape (features x sampleIDs):\", cog_mat.shape)\n",
    "print(\"Example features:\", list(cog_mat.index[:10]))\n",
    "print(\"Example sampleIDs:\", list(cog_mat.columns[:5]))\n",
    "\n",
    "feat = cog_mat.index.astype(str)\n",
    "is_letter_cat = feat.map(lambda x: len(x) == 1 and x.isalpha()).all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c3df8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CASE A: single-letter categories\n",
    "# =========================\n",
    "if is_letter_cat:\n",
    "    cat_sum = cog_mat.groupby(feat).sum()  # category x sampleID\n",
    "    totals = cat_sum.sum(axis=0)           # total per sampleID\n",
    "\n",
    "    top_ids = totals.sort_values(ascending=False).head(N_UUID).index\n",
    "\n",
    "    prop = (cat_sum[top_ids] / totals.loc[top_ids].replace(0, np.nan)).T.fillna(0)  # sampleID x category\n",
    "    cat_order = prop.sum(axis=0).sort_values(ascending=False).index\n",
    "    prop = prop[cat_order]\n",
    "\n",
    "    # ---- stacked bar (mapped labels) ----\n",
    "    fig, ax = plt.subplots(figsize=(22, 8))\n",
    "    x = np.arange(prop.shape[0])\n",
    "    bottom = np.zeros(prop.shape[0])\n",
    "\n",
    "    for c in prop.columns:\n",
    "        vals = prop[c].values\n",
    "        ax.bar(x, vals, bottom=bottom, label=c)\n",
    "        bottom += vals\n",
    "\n",
    "    ax.set_ylim(0, 1.12)\n",
    "    for i, sid in enumerate(prop.index):\n",
    "        ax.text(i, 1.02, f\"{int(totals.loc[sid])}\", ha=\"center\", va=\"bottom\", fontsize=7, clip_on=True)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([make_label(sid) for sid in prop.index], rotation=60, ha=\"right\", fontsize=7)\n",
    "    ax.set_ylabel(\"Proportion of COG categories\")\n",
    "    ax.set_title(f\"COG category composition (Top {N_UUID} samples) — labeled\")\n",
    "\n",
    "    fig.subplots_adjust(bottom=0.40, top=0.72)\n",
    "    ax.legend(ncols=12, bbox_to_anchor=(0.5, 1.32), loc=\"upper center\")\n",
    "\n",
    "    out1 = OUT_DIR / \"cog_category_stackedbar_top_labeled.png\"\n",
    "    fig.savefig(out1, dpi=300)\n",
    "    plt.show()\n",
    "    print(\"Saved:\", out1)\n",
    "\n",
    "    # ---- PCA on categories (all samples) ----\n",
    "    out_full = OUT_DIR / \"cog_category_pca_all_full.png\"\n",
    "    out_zoom = OUT_DIR / \"cog_category_pca_all_zoom.png\"\n",
    "    out_outliers = OUT_DIR / \"cog_category_pca_all_outliers.tsv\"\n",
    "\n",
    "    pca_plot(\n",
    "        cat_sum,  # category x sampleID\n",
    "        title=\"COG category PCA (all samples) — full\",\n",
    "        outpath=out_full,\n",
    "        color_by=\"food\",\n",
    "        zoom_quantile=None\n",
    "    )\n",
    "\n",
    "    pca_plot(\n",
    "        cat_sum,\n",
    "        title=\"COG category PCA (all samples) — zoom (1–99%)\",\n",
    "        outpath=out_zoom,\n",
    "        color_by=\"food\",\n",
    "        zoom_quantile=(0.01, 0.99),\n",
    "        outlier_report_path=out_outliers\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ba057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CASE B: not single-letter categories\n",
    "# =========================\n",
    "if not is_letter_cat:\n",
    "    print(\"⚠️ Features are not single-letter COG categories (J/K/L...). PCA will be run on the feature dimension (colored by food).\")\n",
    "\n",
    "    out_full = OUT_DIR / \"cog_feature_pca_all_full.png\"\n",
    "    out_zoom = OUT_DIR / \"cog_feature_pca_all_zoom.png\"\n",
    "    out_outliers = OUT_DIR / \"cog_feature_pca_all_outliers.tsv\"\n",
    "\n",
    "    pca_plot(\n",
    "        cog_mat,  # feature x sampleID\n",
    "        title=\"COG feature PCA (all samples) — full\",\n",
    "        outpath=out_full,\n",
    "        color_by=\"food\",\n",
    "        zoom_quantile=None\n",
    "    )\n",
    "\n",
    "    pca_plot(\n",
    "        cog_mat,\n",
    "        title=\"COG feature PCA (all samples) — zoom (1–99%)\",\n",
    "        outpath=out_zoom,\n",
    "        color_by=\"food\",\n",
    "        zoom_quantile=(0.01, 0.99),\n",
    "        outlier_report_path=out_outliers\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723620a5",
   "metadata": {},
   "source": [
    "### Step 7. AMR total burden by sample\n",
    "\n",
    "**Figure: bar plot of total AMR signal per sample (Top N).**\n",
    "\n",
    "- **What it is:** The AMR feature table is summed across features to a single total per sample (merging runs where applicable).\n",
    "- **What it shows:** Which samples have a relatively higher overall AMR signal. This is a coarse summary (it does not tell you *which* genes drive the signal).\n",
    "- **Outputs:** A figure file plus a TSV table of the top samples are saved to `figures/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435eafec-68b4-45d6-80d7-b23bbde7b970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# AMR total burden by SAMPLE (merge runs)\n",
    "# Input: FeatureTable[Frequency] amr_ft_bacteria_95.qza\n",
    "# Output:\n",
    "#   figures/amr_total_counts_topSamples.png\n",
    "#   figures/amr_total_topSamples.tsv\n",
    "# =========================\n",
    "\n",
    "# -------------------\n",
    "# paths / params\n",
    "# -------------------\n",
    "DATA_DIR = Path(\"data/07_Functional_analysis/data\")\n",
    "AMR_FT_QZA = DATA_DIR / \"amr_ft_bacteria_95.qza\"\n",
    "\n",
    "# Metadata (for mapping sample -> food/category)\n",
    "META_CANDIDATES = [\n",
    "    Path(\"merged_metadata_filtered.tsv\"),\n",
    "    Path(\"data/merged_metadata_filtered.tsv\"),\n",
    "]\n",
    "META_TSV = next((p for p in META_CANDIDATES if p.exists()), None)\n",
    "\n",
    "OUT_DIR = Path(\"figures\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "EXP_FT  = Path(\"exported/amr_ft\")\n",
    "FT_TSV  = EXP_FT / \"feature-table.tsv\"\n",
    "\n",
    "N_SAMPLES = 25\n",
    "DO_EXPORT = True  # If TSV is already generated and up-to-date, switch this to False\n",
    "\n",
    "# -------------------\n",
    "# helpers\n",
    "# -------------------\n",
    "def read_biom_tsv(tsv_path: Path) -> pd.DataFrame:\n",
    "    # biom convert output: row 1 is a comment, row 2 is the header (#OTU ID + sample IDs)\n",
    "    df = pd.read_csv(tsv_path, sep=\"\\t\", skiprows=1)\n",
    "    df = df.set_index(df.columns[0])\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "    return df  # features x columns(run IDs)\n",
    "\n",
    "def extract_sample(col: str) -> str:\n",
    "    \"\"\"\n",
    "    Column example:\n",
    "      PB_MS001-3/01486816-...\n",
    "      IL_A001/71779113-...\n",
    "    Return sample name without platform prefix and without /uuid:\n",
    "      MS001-3, A001, ...\n",
    "    \"\"\"\n",
    "    left = str(col).split(\"/\", 1)[0]\n",
    "    left = left.replace(\"PB_\", \"\", 1).replace(\"IL_\", \"\", 1)\n",
    "    return left\n",
    "\n",
    "def load_metadata(meta_path: Path | None) -> pd.DataFrame | None:\n",
    "    if meta_path is None:\n",
    "        print(\"Warning: merged_metadata_filtered.tsv not found. Will plot without food/category labels.\")\n",
    "        return None\n",
    "    meta = pd.read_csv(meta_path, sep=\"\\t\", dtype=str)\n",
    "    # Standardize the sample_ID column name\n",
    "    if \"sample_ID\" not in meta.columns:\n",
    "        # Fallback: look for similar column names\n",
    "        for c in meta.columns:\n",
    "            if c.lower() in [\"sample-id\", \"sampleid\", \"#sampleid\", \"sample_id\"]:\n",
    "                meta = meta.rename(columns={c: \"sample_ID\"})\n",
    "                break\n",
    "    if \"sample_ID\" not in meta.columns:\n",
    "        print(f\"Warning: metadata has no sample_ID column. Columns: {meta.columns.tolist()}\")\n",
    "        return None\n",
    "    meta[\"sample_ID\"] = meta[\"sample_ID\"].astype(str)\n",
    "    return meta\n",
    "\n",
    "def build_sample_meta_maps(meta: pd.DataFrame | None):\n",
    "    if meta is None:\n",
    "        return {}, {}\n",
    "    food_col = \"fermented_food_type\" if \"fermented_food_type\" in meta.columns else None\n",
    "    cat_col  = \"category\" if \"category\" in meta.columns else None\n",
    "\n",
    "    sample2food = {}\n",
    "    if food_col:\n",
    "        sample2food = meta.drop_duplicates(\"sample_ID\").set_index(\"sample_ID\")[food_col].to_dict()\n",
    "\n",
    "    sample2cat = {}\n",
    "    if cat_col:\n",
    "        sample2cat = meta.drop_duplicates(\"sample_ID\").set_index(\"sample_ID\")[cat_col].to_dict()\n",
    "\n",
    "    print(\"Metadata mapping columns:\",\n",
    "          \"food=\" + (food_col if food_col else \"NA\"),\n",
    "          \"category=\" + (cat_col if cat_col else \"NA\"))\n",
    "    return sample2food, sample2cat\n",
    "\n",
    "def make_sample_label(sample: str, sample2food: dict) -> str:\n",
    "    food = sample2food.get(sample, \"NA\")\n",
    "    return f\"{sample} | {food}\" if food != \"NA\" else sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc18fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# export qza -> tsv (optional)\n",
    "# -------------------\n",
    "if DO_EXPORT or (not FT_TSV.exists()):\n",
    "    if EXP_FT.exists():\n",
    "        shutil.rmtree(EXP_FT)\n",
    "    EXP_FT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    subprocess.run(\n",
    "        [\"qiime\", \"tools\", \"export\", \"--input-path\", str(AMR_FT_QZA), \"--output-path\", str(EXP_FT)],\n",
    "        check=True\n",
    "    )\n",
    "    subprocess.run(\n",
    "        [\"biom\", \"convert\", \"-i\", str(EXP_FT / \"feature-table.biom\"), \"-o\", str(FT_TSV), \"--to-tsv\"],\n",
    "        check=True\n",
    "    )\n",
    "\n",
    "print(\"Using TSV:\", FT_TSV)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d391550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# load AMR table\n",
    "# -------------------\n",
    "amr_mat = read_biom_tsv(FT_TSV)\n",
    "\n",
    "# total per run\n",
    "totals_run = amr_mat.sum(axis=0)  # index = run IDs (columns)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"run\": totals_run.index.astype(str),\n",
    "    \"amr_total\": totals_run.values\n",
    "})\n",
    "df[\"sample_ID\"] = df[\"run\"].map(extract_sample)\n",
    "\n",
    "# merge runs -> sample\n",
    "by_sample = (\n",
    "    df.groupby(\"sample_ID\", as_index=True)[\"amr_total\"]\n",
    "      .sum()\n",
    "      .sort_values(ascending=False)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95351bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# attach food/category\n",
    "# -------------------\n",
    "meta = load_metadata(META_TSV)\n",
    "sample2food, sample2cat = build_sample_meta_maps(meta)\n",
    "\n",
    "by_sample_df = by_sample.to_frame(\"amr_total_sum_runs\")\n",
    "by_sample_df[\"food\"] = [sample2food.get(s, \"NA\") for s in by_sample_df.index]\n",
    "by_sample_df[\"category\"] = [sample2cat.get(s, \"NA\") for s in by_sample_df.index]\n",
    "\n",
    "# -------------------\n",
    "# plot Top N samples\n",
    "# -------------------\n",
    "top_df = by_sample_df.head(N_SAMPLES).copy()\n",
    "\n",
    "labels = [make_sample_label(s, sample2food) for s in top_df.index]\n",
    "values = top_df[\"amr_total_sum_runs\"].values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "x = np.arange(len(top_df))\n",
    "ax.bar(x, values)\n",
    "\n",
    "ymax = values.max() if values.max() > 0 else 1\n",
    "ax.set_ylim(0, ymax * 1.15)\n",
    "\n",
    "for i, v in enumerate(values):\n",
    "    ax.text(i, v + ymax * 0.02, f\"{int(v)}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=60, ha=\"right\", fontsize=7)\n",
    "ax.set_ylabel(\"Total AMR hits (summed across runs)\")\n",
    "ax.set_title(f\"AMR burden (Top {N_SAMPLES} samples) — labeled & counts annotated\")\n",
    "fig.subplots_adjust(bottom=0.35)\n",
    "\n",
    "out_fig = OUT_DIR / \"amr_total_counts_topSamples.png\"\n",
    "fig.savefig(out_fig, dpi=300)\n",
    "plt.show()\n",
    "print(\"Saved:\", out_fig)\n",
    "\n",
    "# -------------------\n",
    "# save table\n",
    "# -------------------\n",
    "out_tsv = OUT_DIR / \"amr_total_topSamples.tsv\"\n",
    "top_df.reset_index().rename(columns={\"index\": \"sample_ID\"}).to_csv(out_tsv, sep=\"\\t\", index=False)\n",
    "print(\"Saved:\", out_tsv)\n",
    "\n",
    "display(top_df.reset_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd6b3ce",
   "metadata": {},
   "source": [
    "### Step 8. AMR additional summaries\n",
    "\n",
    "**Figures: grouped distribution plots of AMR totals (boxplot + points), optionally on a log scale.**\n",
    "\n",
    "- **What it is:** AMR totals are compared across metadata groups (e.g., fermented food type).  \n",
    "  The **box** summarizes median + IQR, and the overlaid **points** show individual samples.\n",
    "- **What it shows:** Differences in the distribution of AMR totals between groups, plus within-group variability and outliers (visible as points).\n",
    "- **Tip:** Use the log-scale version when totals span orders of magnitude, to avoid the plot being dominated by a few large values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039b0662-7c76-4f89-adac-1a44af58ec94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# =========================\n",
    "# 0) Config\n",
    "# =========================\n",
    "DATA_DIR = Path(\"data/07_Functional_analysis/data\")\n",
    "AMR_FT_QZA = DATA_DIR / \"amr_ft_bacteria_95.qza\"\n",
    "\n",
    "OUT_DIR = Path(\"figures\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "EXP_FT  = Path(\"exported/amr_ft\")\n",
    "FT_TSV  = EXP_FT / \"feature-table.tsv\"\n",
    "\n",
    "# Metadata (auto-detect two common locations)\n",
    "META_CANDIDATES = [Path(\"merged_metadata_filtered.tsv\"), Path(\"data/merged_metadata_filtered.tsv\")]\n",
    "META_TSV = next((p for p in META_CANDIDATES if p.exists()), None)\n",
    "\n",
    "DO_EXPORT = True   # If TSV is already exported and up-to-date, you can set this to False\n",
    "TOP_N = 25         # Top samples barplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4751d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Helpers\n",
    "# =========================\n",
    "def read_biom_tsv(tsv_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"biom convert output: row 1 is a comment, row 2 is the header (#OTU ID + sample IDs).\"\"\"\n",
    "    df = pd.read_csv(tsv_path, sep=\"\\t\", skiprows=1)\n",
    "    df = df.set_index(df.columns[0])\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "    return df  # features x columns(run IDs)\n",
    "\n",
    "def extract_sample(col: str) -> str:\n",
    "    \"\"\"\n",
    "    Column example:\n",
    "      PB_MS001-3/01486816-...\n",
    "      IL_A001/71779113-...\n",
    "    Return sample_ID (strip platform prefix + strip /uuid):\n",
    "      MS001-3, A001, ...\n",
    "    \"\"\"\n",
    "    left = str(col).split(\"/\", 1)[0]\n",
    "    left = left.replace(\"PB_\", \"\", 1).replace(\"IL_\", \"\", 1)\n",
    "    return left\n",
    "\n",
    "def extract_platform(col: str) -> str:\n",
    "    left = str(col).split(\"/\", 1)[0]\n",
    "    if left.startswith(\"PB_\"):\n",
    "        return \"PB\"\n",
    "    if left.startswith(\"IL_\"):\n",
    "        return \"IL\"\n",
    "    return \"NA\"\n",
    "\n",
    "def load_metadata(meta_path: Path | None) -> pd.DataFrame | None:\n",
    "    if meta_path is None:\n",
    "        print(\"❗ Warning: merged_metadata_filtered.tsv not found. Will plot without food/category.\")\n",
    "        return None\n",
    "    meta = pd.read_csv(meta_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "    # normalize sample_ID col\n",
    "    if \"sample_ID\" not in meta.columns:\n",
    "        for c in meta.columns:\n",
    "            if c.lower() in [\"sample-id\", \"sampleid\", \"#sampleid\", \"sample_id\"]:\n",
    "                meta = meta.rename(columns={c: \"sample_ID\"})\n",
    "                break\n",
    "    if \"sample_ID\" not in meta.columns:\n",
    "        print(\"❗ Warning: metadata has no sample_ID column. Columns:\", meta.columns.tolist())\n",
    "        return None\n",
    "\n",
    "    meta[\"sample_ID\"] = meta[\"sample_ID\"].astype(str)\n",
    "    return meta\n",
    "\n",
    "def annotate_bars(ax, values, pad_frac=0.03, fontsize=8, fmt=None):\n",
    "    \"\"\"\n",
    "    values: array-like\n",
    "    fmt: None -> int; or callable(v)->str\n",
    "    \"\"\"\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    vmax = float(np.nanmax(values)) if len(values) else 0.0\n",
    "    if not np.isfinite(vmax) or vmax <= 0:\n",
    "        vmax = 1.0\n",
    "\n",
    "    # Increase the y-axis upper limit to leave room for labels\n",
    "    ax.set_ylim(0, vmax * 1.30)\n",
    "\n",
    "    if fmt is None:\n",
    "        fmt = lambda v: f\"{int(round(v))}\"\n",
    "\n",
    "    for i, v in enumerate(values):\n",
    "        ax.text(\n",
    "            i, v + vmax * pad_frac,\n",
    "            fmt(v),\n",
    "            ha=\"center\", va=\"bottom\",\n",
    "            fontsize=fontsize,\n",
    "            clip_on=True\n",
    "        )\n",
    "\n",
    "def make_label(sample_id: str, food: str | float) -> str:\n",
    "    if pd.notna(food):\n",
    "        return f\"{sample_id} | {food}\"\n",
    "    return str(sample_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638d95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2) Export qza -> tsv (only if needed)\n",
    "# =========================\n",
    "if DO_EXPORT or (not FT_TSV.exists()):\n",
    "    if EXP_FT.exists():\n",
    "        shutil.rmtree(EXP_FT)\n",
    "    EXP_FT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    subprocess.run(\n",
    "        [\"qiime\", \"tools\", \"export\", \"--input-path\", str(AMR_FT_QZA), \"--output-path\", str(EXP_FT)],\n",
    "        check=True\n",
    "    )\n",
    "    subprocess.run(\n",
    "        [\"biom\", \"convert\", \"-i\", str(EXP_FT / \"feature-table.biom\"), \"-o\", str(FT_TSV), \"--to-tsv\"],\n",
    "        check=True\n",
    "    )\n",
    "\n",
    "print(\"Using AMR TSV:\", FT_TSV)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa46f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3) Build per-sample AMR totals (merge PB/IL runs)\n",
    "# =========================\n",
    "amr_mat = read_biom_tsv(FT_TSV)\n",
    "\n",
    "# total per run/column\n",
    "totals_run = amr_mat.sum(axis=0)  # index=run columns\n",
    "\n",
    "runs = pd.DataFrame({\n",
    "    \"run_col\": totals_run.index.astype(str),\n",
    "    \"platform\": [extract_platform(c) for c in totals_run.index.astype(str)],\n",
    "    \"sample_ID\": [extract_sample(c) for c in totals_run.index.astype(str)],\n",
    "    \"amr_total_run\": totals_run.values\n",
    "})\n",
    "\n",
    "# merge runs -> sample\n",
    "sample_totals = runs.groupby(\"sample_ID\")[\"amr_total_run\"].sum().sort_values(ascending=False)\n",
    "sample_nruns  = runs.groupby(\"sample_ID\")[\"run_col\"].nunique()\n",
    "\n",
    "sample_df = pd.DataFrame({\n",
    "    \"amr_total_sum_runs\": sample_totals,\n",
    "    \"n_runs\": sample_nruns.reindex(sample_totals.index).fillna(0).astype(int)\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a80c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4) Attach metadata (food/category)\n",
    "# =========================\n",
    "meta = load_metadata(META_TSV)\n",
    "if meta is not None:\n",
    "    FOOD_COL = \"fermented_food_type\" if \"fermented_food_type\" in meta.columns else None\n",
    "    CAT_COL  = \"category\" if \"category\" in meta.columns else None\n",
    "\n",
    "    meta1 = meta.drop_duplicates(\"sample_ID\").set_index(\"sample_ID\")\n",
    "\n",
    "    if FOOD_COL:\n",
    "        sample_df[\"fermented_food_type\"] = sample_df.index.map(meta1[FOOD_COL])\n",
    "    else:\n",
    "        sample_df[\"fermented_food_type\"] = np.nan\n",
    "\n",
    "    if CAT_COL:\n",
    "        sample_df[\"category\"] = sample_df.index.map(meta1[CAT_COL])\n",
    "    else:\n",
    "        sample_df[\"category\"] = np.nan\n",
    "else:\n",
    "    sample_df[\"fermented_food_type\"] = np.nan\n",
    "    sample_df[\"category\"] = np.nan\n",
    "\n",
    "display(sample_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21652c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5) Plot A: Top N samples barplot# =========================\n",
    "top = sample_df.head(TOP_N).copy()\n",
    "\n",
    "labels = [make_label(s, top.loc[s, \"fermented_food_type\"]) for s in top.index]\n",
    "vals = top[\"amr_total_sum_runs\"].values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "x = np.arange(len(top))\n",
    "ax.bar(x, vals)\n",
    "\n",
    "# ✅ Fix: the label for the tallest bar was clipped\n",
    "annotate_bars(ax, vals, pad_frac=0.03, fontsize=8)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=60, ha=\"right\", fontsize=7)\n",
    "ax.set_ylabel(\"Total AMR hits (summed across runs)\")\n",
    "ax.set_title(f\"AMR burden — Top {TOP_N} samples (labeled)\")\n",
    "fig.subplots_adjust(bottom=0.35)\n",
    "\n",
    "out_fig = OUT_DIR / \"amr_total_topSamples_bar_labeled.png\"\n",
    "fig.savefig(out_fig, dpi=300)\n",
    "plt.show()\n",
    "print(\"Saved:\", out_fig)\n",
    "\n",
    "out_tsv = OUT_DIR / \"amr_total_topSamples_table.tsv\"\n",
    "top.reset_index().rename(columns={\"index\":\"sample_ID\"}).to_csv(out_tsv, sep=\"\\t\", index=False)\n",
    "print(\"Saved:\", out_tsv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a97381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 6) Grouped plots: boxplot + jittered points (+ log version)\n",
    "# =========================\n",
    "def box_with_points(df: pd.DataFrame,\n",
    "                    group_col: str,\n",
    "                    value_col: str = \"amr_total_sum_runs\",\n",
    "                    min_n: int = 2,               # groups with n < min_n are merged into \"Other\"\n",
    "                    order_by: str = \"median\",     # median/mean\n",
    "                    use_log: bool = False,\n",
    "                    prefix: str = \"amr\"):\n",
    "    if group_col not in df.columns:\n",
    "        print(f\"Skip {group_col}: column not in sample_df\")\n",
    "        return\n",
    "\n",
    "    d = df.dropna(subset=[group_col, value_col]).copy()\n",
    "    if d.empty:\n",
    "        print(f\"Skip {group_col}: no non-NA values\")\n",
    "        return\n",
    "\n",
    "    # Merge small groups\n",
    "    counts = d[group_col].value_counts()\n",
    "    small = counts[counts < min_n].index\n",
    "    if len(small) > 0:\n",
    "        d[group_col] = d[group_col].where(~d[group_col].isin(small), other=f\"Other (n<{min_n})\")\n",
    "\n",
    "    # Sort\n",
    "    if order_by == \"mean\":\n",
    "        stat = d.groupby(group_col)[value_col].mean()\n",
    "    else:\n",
    "        stat = d.groupby(group_col)[value_col].median()\n",
    "    order = stat.sort_values(ascending=False).index.tolist()\n",
    "\n",
    "    data = [d.loc[d[group_col] == g, value_col].values for g in order]\n",
    "    ns = [len(v) for v in data]\n",
    "\n",
    "    fig_w = max(10, 0.6 * len(order))\n",
    "    fig, ax = plt.subplots(figsize=(fig_w, 5.5))\n",
    "\n",
    "    # boxplot\n",
    "    ax.boxplot(\n",
    "        data,\n",
    "        labels=[f\"{g} (n={n})\" for g, n in zip(order, ns)],\n",
    "        showfliers=False\n",
    "    )\n",
    "\n",
    "    # Jittered points (n=1 is still visible)\n",
    "    rng = np.random.default_rng(0)\n",
    "    for i, vals_i in enumerate(data, start=1):\n",
    "        jitter = rng.uniform(-0.18, 0.18, size=len(vals_i))\n",
    "        ax.scatter(np.full(len(vals_i), i) + jitter, vals_i, alpha=0.75, s=22)\n",
    "\n",
    "    ax.set_ylabel(\"Total AMR hits per sample (sum runs)\")\n",
    "    ax.set_title(f\"AMR burden by {group_col} (box + points){' [log10]' if use_log else ''}\")\n",
    "    ax.tick_params(axis=\"x\", rotation=45)\n",
    "    for t in ax.get_xticklabels():\n",
    "        t.set_ha(\"right\")\n",
    "\n",
    "    if use_log:\n",
    "        # If there are zeros, log-scale breaks; for display replace <= 0 with 0.5\n",
    "        ymin = np.min(np.concatenate(data)) if len(data) else 1\n",
    "        if ymin <= 0:\n",
    "            print(\"Warning: non-positive values detected; using log scale after replacing <=0 with 0.5 for display.\")\n",
    "            ax.set_yscale(\"log\")\n",
    "        else:\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    suffix = \"log\" if use_log else \"linear\"\n",
    "    out = OUT_DIR / f\"{prefix}_{group_col}_box_points_{suffix}.png\"\n",
    "    fig.savefig(out, dpi=300)\n",
    "    plt.show()\n",
    "    print(\"Saved:\", out)\n",
    "\n",
    "def bar_by_group(df: pd.DataFrame,\n",
    "                 group_col: str,\n",
    "                 stat: str = \"median\",          # sum/mean/median\n",
    "                 value_col: str = \"amr_total_sum_runs\",\n",
    "                 min_n: int = 2,\n",
    "                 prefix: str = \"amr\"):\n",
    "    if group_col not in df.columns:\n",
    "        print(f\"Skip {group_col}: column not in df\")\n",
    "        return\n",
    "\n",
    "    d = df.dropna(subset=[group_col, value_col]).copy()\n",
    "    if d.empty:\n",
    "        print(f\"Skip {group_col}: no non-NA values\")\n",
    "        return\n",
    "\n",
    "    # Merge small groups\n",
    "    counts = d[group_col].value_counts()\n",
    "    small = counts[counts < min_n].index\n",
    "    if len(small) > 0:\n",
    "        d[group_col] = d[group_col].where(~d[group_col].isin(small), other=f\"Other (n<{min_n})\")\n",
    "\n",
    "    # Summary statistics\n",
    "    if stat == \"sum\":\n",
    "        s = d.groupby(group_col)[value_col].sum()\n",
    "        ylab = \"Total AMR hits (sum across samples)\"\n",
    "        fmt = lambda v: f\"{int(round(v))}\"\n",
    "    elif stat == \"mean\":\n",
    "        s = d.groupby(group_col)[value_col].mean()\n",
    "        ylab = \"Mean AMR hits per sample\"\n",
    "        fmt = lambda v: f\"{v:.1f}\"\n",
    "    elif stat == \"median\":\n",
    "        s = d.groupby(group_col)[value_col].median()\n",
    "        ylab = \"Median AMR hits per sample\"\n",
    "        fmt = lambda v: f\"{v:.1f}\"\n",
    "    else:\n",
    "        raise ValueError(\"stat must be one of: sum/mean/median\")\n",
    "\n",
    "    # Sorting: using the median is more stable\n",
    "    order = d.groupby(group_col)[value_col].median().sort_values(ascending=False).index.tolist()\n",
    "    s = s.reindex(order)\n",
    "\n",
    "    # Annotate n=\n",
    "    n_map = d[group_col].value_counts().to_dict()\n",
    "    xlabels = [f\"{g} (n={int(n_map.get(g,0))})\" for g in s.index]\n",
    "\n",
    "    fig_w = max(10, 0.6 * len(s))\n",
    "    fig, ax = plt.subplots(figsize=(fig_w, 5))\n",
    "    x = np.arange(len(s))\n",
    "    ax.bar(x, s.values)\n",
    "\n",
    "    # ✅ Annotate in the correct format in one pass; no need to clear()\n",
    "    annotate_bars(ax, s.values, pad_frac=0.03, fontsize=8, fmt=fmt)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(xlabels, rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel(ylab)\n",
    "    ax.set_title(f\"AMR burden by {group_col} ({stat.upper()})\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    out = OUT_DIR / f\"{prefix}_{group_col}_bar_{stat}.png\"\n",
    "    fig.savefig(out, dpi=300)\n",
    "    plt.show()\n",
    "    print(\"Saved:\", out)\n",
    "\n",
    "    out_tab = OUT_DIR / f\"{prefix}_{group_col}_{stat}.tsv\"\n",
    "    pd.DataFrame({group_col: list(s.index), stat: s.values}).to_csv(out_tab, sep=\"\\t\", index=False)\n",
    "    print(\"Saved:\", out_tab)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67440a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- fermented_food_type ----\n",
    "box_with_points(sample_df, \"fermented_food_type\", min_n=2, use_log=False, prefix=\"amr\")\n",
    "box_with_points(sample_df, \"fermented_food_type\", min_n=2, use_log=True,  prefix=\"amr\")\n",
    "\n",
    "bar_by_group(sample_df, \"fermented_food_type\", stat=\"sum\",    min_n=2, prefix=\"amr\")\n",
    "bar_by_group(sample_df, \"fermented_food_type\", stat=\"mean\",   min_n=2, prefix=\"amr\")\n",
    "bar_by_group(sample_df, \"fermented_food_type\", stat=\"median\", min_n=2, prefix=\"amr\")\n",
    "\n",
    "# ---- category (if exists) ----\n",
    "if \"category\" in sample_df.columns:\n",
    "    box_with_points(sample_df, \"category\", min_n=2, use_log=False, prefix=\"amr\")\n",
    "    box_with_points(sample_df, \"category\", min_n=2, use_log=True,  prefix=\"amr\")\n",
    "\n",
    "    bar_by_group(sample_df, \"category\", stat=\"sum\",    min_n=2, prefix=\"amr\")\n",
    "    bar_by_group(sample_df, \"category\", stat=\"mean\",   min_n=2, prefix=\"amr\")\n",
    "    bar_by_group(sample_df, \"category\", stat=\"median\", min_n=2, prefix=\"amr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc6e9d0-c5b1-47d3-8f25-2b072b302aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QIIME 2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
