{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1a54645",
   "metadata": {},
   "source": [
    "# Genome Size Analysis\n",
    "### Assembled genome size (bp) per MAG, compared across sequencing techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5153db1e",
   "metadata": {},
   "source": [
    "This notebook documents the workflow used to:\n",
    "\n",
    "- Load and validate `Metadata_Extended.tsv`\n",
    "- Summarize **MAG yield per sample** (counts) across sequencing techniques\n",
    "- Compute **assembled genome size** (bp) per MAG by summing contig lengths in each MAG FASTA\n",
    "- Compare genome-size distributions between **Illumina** and **PacBio**\n",
    "- Export merged tables for downstream analyses (e.g., QIIME2 / diversity workflows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72135dd7",
   "metadata": {},
   "source": [
    "#### **Goal**\n",
    "\n",
    "**Quantify and compare reconstructed MAG properties between sequencing techniques**  \n",
    "(specifically: *MAG yield per sample* and *assembled genome size per MAG*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3465ad",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red; padding:10px; color:red; font-weight:bold;\">\n",
    "Note: Some commands (e.g., downloading data archives) are kept in the notebook but may be commented out depending on your environment.  \n",
    "Genome-size computation scans FASTA files on disk (default: <code>data/raw</code>, fallback: <code>data/</code>).  \n",
    "If your MAG FASTA files live elsewhere, update <code>SEARCH_ROOTS</code> in <b>Step 3</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83ebc8",
   "metadata": {},
   "source": [
    "#### **Notebook Content:** ####\n",
    "- [Prepare Environment](#prepare-environment)\n",
    "- [Load and Validate Metadata](#step-1-load-and-validate-metadata)\n",
    "- [MAG Yield per Sample](#step-2-mag-yield-per-sample)\n",
    "- [Compute Genome Size from FASTA](#step-3-compute-genome-size-from-fasta)\n",
    "- [QC + Merge](#step-4-qc--merge)\n",
    "- [Summaries](#step-5-summaries)\n",
    "- [Visualizations](#step-6-visualizations)\n",
    "- [Exports](#step-7-exports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69950829",
   "metadata": {},
   "source": [
    "### **The workflow** ###\n",
    "\n",
    "1. **Prepare environment** (imports, folders, optional data download)\n",
    "2. **Load and validate metadata** (`sample-id`, `sample`, `mag-id`)\n",
    "3. **Summarize MAG yield per sample** (and whether samples were sequenced by both techniques)\n",
    "4. **Compute genome sizes** from MAG FASTA files\n",
    "5. **QC + merge** genome-size results back into metadata\n",
    "6. **Summarize + visualize** distributions (log-scale options)\n",
    "7. **Export** merged tables / summary outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22b181",
   "metadata": {},
   "source": [
    "### Prepare Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af881bf8",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b032c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-18 23:18:59--  https://polybox.ethz.ch/index.php/s/nMa2WaWEDft3kMr/download\n",
      "Resolving polybox.ethz.ch (polybox.ethz.ch)... 129.132.71.243\n",
      "Connecting to polybox.ethz.ch (polybox.ethz.ch)|129.132.71.243|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 278 [application/zip]\n",
      "Saving to: ‘data/Download.zip’\n",
      "\n",
      "data/Download.zip   100%[===================>]     278  --.-KB/s    in 0s      \n",
      "\n",
      "2025-12-18 23:18:59 (358 MB/s) - ‘data/Download.zip’ saved [278/278]\n",
      "\n",
      "Archive:  data/Download.zip\n",
      "   creating: data/01_Data_Exploration/\n"
     ]
    }
   ],
   "source": [
    "#set up environment\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from qiime2 import Visualization\n",
    "import qiime2 as q2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create directories for the notebook. DO NOT change\n",
    "data_dir = \"data/processed/01.3_Genome_size\"\n",
    "raw_data = \"data/raw\"\n",
    "metadata_dir = \"data/processed/metadata\"\n",
    "out_dir = Path(data_dir)\n",
    "\n",
    "!mkdir -p data\n",
    "!mkdir -p $raw_data\n",
    "!mkdir -p $metadata_dir\n",
    "!mkdir -p $data_dir\n",
    "\n",
    "# fetches useful files for the current notebook. All files will be saved in `data/`\n",
    "!wget 'https://polybox.ethz.ch/index.php/s/nMa2WaWEDft3kMr/download' -O data/Download.zip\n",
    "!unzip -o data/Download.zip -d data\n",
    "!rm data/Download.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957c5c2a",
   "metadata": {},
   "source": [
    "### Step 1. Load and validate metadata\n",
    "\n",
    "We load the project metadata table (generated in earlier preprocessing).  \n",
    "Downstream steps assume at least these columns exist:\n",
    "\n",
    "- `sample-id` (e.g., `IL_...` / `PB_...`)\n",
    "- `sample` (biological sample identifier)\n",
    "- `mag-id` (MAG identifier used in FASTA filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb44fb19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Metadata file not found: data/processed/metadata/Metadata_Extended.tsv\nMake sure you downloaded/unzipped the project data and that metadata_dir is correct.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m meta_path \u001b[38;5;241m=\u001b[39m Path(metadata_dir) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata_Extended.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m meta_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure you downloaded/unzipped the project data and that metadata_dir is correct.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      9\u001b[0m metadata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(meta_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m required_cols \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample-id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmag-id\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Metadata file not found: data/processed/metadata/Metadata_Extended.tsv\nMake sure you downloaded/unzipped the project data and that metadata_dir is correct."
     ]
    }
   ],
   "source": [
    "# Load metadata (expected output of earlier preprocessing)\n",
    "meta_path = Path(metadata_dir) / \"Metadata_Extended.tsv\"\n",
    "if not meta_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Metadata file not found: {meta_path}\\n\"\n",
    "        \"Make sure you downloaded/unzipped the project data and that metadata_dir is correct.\"\n",
    "    )\n",
    "\n",
    "metadata = pd.read_csv(meta_path, sep=\"\\t\")\n",
    "\n",
    "required_cols = {\"sample-id\", \"sample\", \"mag-id\"}\n",
    "missing = sorted(required_cols - set(metadata.columns))\n",
    "if missing:\n",
    "    raise ValueError(f\"Metadata_Extended.tsv is missing required columns: {missing}\")\n",
    "\n",
    "metadata[list(required_cols)].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7747c407",
   "metadata": {},
   "source": [
    "### Step 2. MAG yield per sample\n",
    "\n",
    "This section answers two quick “sanity” questions before we look at genome sizes:\n",
    "\n",
    "- Do **Illumina** and **PacBio** produce different numbers of MAGs per sample?\n",
    "- Are all biological samples (`sample`) sequenced by **both** techniques?\n",
    "\n",
    "We infer sequencing technique from the `sample-id` prefix (`IL_` vs `PB_`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd4de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper shared across the notebook\n",
    "def infer_technique(sample_id: str) -> str:\n",
    "    \"\"\"Infer sequencing technique from `sample-id` prefix.\"\"\"\n",
    "    s = str(sample_id).upper()\n",
    "    if s.startswith(\"PB_\"):\n",
    "        return \"PacBio\"\n",
    "    if s.startswith(\"IL_\"):\n",
    "        return \"Illumina\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "meta = metadata.copy()\n",
    "meta[\"sample-id\"] = meta[\"sample-id\"].astype(str).str.strip()\n",
    "meta[\"sample\"] = meta[\"sample\"].astype(str).str.strip()\n",
    "meta[\"mag-id\"] = meta[\"mag-id\"].astype(str).str.strip()\n",
    "\n",
    "meta[\"technique\"] = meta[\"sample-id\"].map(infer_technique)\n",
    "\n",
    "# Keep a clean metadata slice for downstream merges (one row per MAG entry)\n",
    "base_meta = meta.loc[:, [\"sample-id\", \"sample\", \"mag-id\", \"technique\"]].copy()\n",
    "\n",
    "# MAG yield per sequencing run (sample-id)\n",
    "mags_per_run = (\n",
    "    meta.groupby([\"sample-id\", \"technique\"])[\"mag-id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"n_mags\")\n",
    ")\n",
    "\n",
    "# MAG yield per biological sample (sample) + technique\n",
    "mags_per_sample = (\n",
    "    meta.groupby([\"sample\", \"technique\"])[\"mag-id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"n_mags\")\n",
    ")\n",
    "\n",
    "# Which biological samples have both techniques?\n",
    "tech_by_sample = (\n",
    "    mags_per_sample.groupby(\"sample\")[\"technique\"]\n",
    "    .apply(lambda s: sorted(set(s)))\n",
    "    .reset_index(name=\"techniques_present\")\n",
    ")\n",
    "tech_by_sample[\"has_both\"] = tech_by_sample[\"techniques_present\"].apply(\n",
    "    lambda xs: (\"Illumina\" in xs) and (\"PacBio\" in xs)\n",
    ")\n",
    "\n",
    "print(\"Biological samples (unique `sample`):\", tech_by_sample.shape[0])\n",
    "print(\"Sequenced by both techniques:\", int(tech_by_sample[\"has_both\"].sum()))\n",
    "print(\"Only one technique:\", int((~tech_by_sample[\"has_both\"]).sum()))\n",
    "\n",
    "mags_per_sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f68b6e8",
   "metadata": {},
   "source": [
    "### Step 3. Compute genome size from FASTA\n",
    "\n",
    "We compute **assembled genome size (bp)** by summing contig lengths in each MAG FASTA.\n",
    "\n",
    "**Matching rule (robust + simple):**\n",
    "- FASTA filename begins with `mag-id` from metadata (exact match or prefix + separator)\n",
    "- `sample-id` is inferred from the directory tree (exact match / regex extraction / `sample` name fallback)\n",
    "\n",
    "If you have multiple FASTA candidates for the same `(sample-id, mag-id)`, we keep the **largest file**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7934ffd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import gzip\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Step 3. Compute genome size from FASTA\n",
    "# We scan FASTA files under SEARCH_ROOTS and compute assembled size (bp) per MAG.\n",
    "# Matching:\n",
    "#   - FASTA filename begins with a metadata `mag-id` (exact or prefix + separator)\n",
    "#   - `sample-id` is inferred from the directory tree\n",
    "\n",
    "FASTA_PATTERNS = (\"*.fa\", \"*.fna\", \"*.fasta\", \"*.fa.gz\", \"*.fna.gz\", \"*.fasta.gz\")\n",
    "\n",
    "# Prefer Setup-defined `raw_data` (often data/raw). Fall back to data/ if needed.\n",
    "SEARCH_ROOTS = [Path(raw_data), Path(\"data\")]\n",
    "\n",
    "# --- Light-weight helpers ------------------------------------------------\n",
    "\n",
    "if \"infer_technique\" not in globals():\n",
    "    def infer_technique(sample_id: str) -> str:\n",
    "        \"\"\"Infer sequencing technique from `sample-id` prefix.\"\"\"\n",
    "        s = str(sample_id).upper()\n",
    "        if s.startswith(\"PB_\"):\n",
    "            return \"PacBio\"\n",
    "        if s.startswith(\"IL_\"):\n",
    "            return \"Illumina\"\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Trim whitespace early: most FASTA/metadata mismatches come from invisible spaces.\n",
    "meta = metadata.loc[:, [\"sample-id\", \"sample\", \"mag-id\"]].copy()\n",
    "meta[\"sample-id\"] = meta[\"sample-id\"].astype(str).str.strip()\n",
    "meta[\"sample\"] = meta[\"sample\"].astype(str).str.strip()\n",
    "meta[\"mag-id\"] = meta[\"mag-id\"].astype(str).str.strip()\n",
    "\n",
    "sample_id_set = set(meta[\"sample-id\"])\n",
    "mag_id_set = set(meta[\"mag-id\"])\n",
    "\n",
    "# Some folder structures use `sample` rather than `sample-id`; allow a safe fallback only when unambiguous.\n",
    "sample_to_sample_ids = (\n",
    "    meta.groupby(\"sample\")[\"sample-id\"]\n",
    "    .apply(lambda s: sorted(set(s)))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "_SAMPLE_ID_RE = re.compile(r\"^(PB|IL)_[A-Za-z0-9]+\", re.IGNORECASE)\n",
    "_BOUNDARY = set(\"._-\")  # common separators after mag-id in filenames\n",
    "\n",
    "# Pre-compute mag-id lengths for fast prefix checks (avoids scanning all mag-ids per file).\n",
    "_mag_lens = sorted({len(m) for m in mag_id_set}, reverse=True)\n",
    "\n",
    "def _strip_fasta_suffix(filename: str) -> str:\n",
    "    \"\"\"Remove .gz and FASTA extension; return the remaining basename.\"\"\"\n",
    "    base = filename\n",
    "    if base.endswith(\".gz\"):\n",
    "        base = base[:-3]\n",
    "    for ext in (\".fa\", \".fna\", \".fasta\"):\n",
    "        if base.endswith(ext):\n",
    "            base = base[: -len(ext)]\n",
    "            break\n",
    "    return base\n",
    "\n",
    "def match_mag_id_from_file(path: Path) -> Optional[str]:\n",
    "    \"\"\"Return matched metadata `mag-id` if filename begins with it; else None.\"\"\"\n",
    "    base = _strip_fasta_suffix(path.name)\n",
    "\n",
    "    # Exact: filename == mag-id\n",
    "    if base in mag_id_set:\n",
    "        return base\n",
    "\n",
    "    # Prefix + boundary: mag-id + ('_', '.', '-') + anything\n",
    "    for L in _mag_lens:\n",
    "        if len(base) < L:\n",
    "            continue\n",
    "        prefix = base[:L]\n",
    "        if prefix in mag_id_set and (len(base) == L or base[L] in _BOUNDARY):\n",
    "            return prefix\n",
    "    return None\n",
    "\n",
    "def infer_sample_id_from_path(path: Path) -> Optional[str]:\n",
    "    \"\"\"Infer `sample-id` from directory components (exact match / regex / sample-name fallback).\"\"\"\n",
    "    # 1) Exact match against metadata sample-ids\n",
    "    for part in path.parts[::-1]:\n",
    "        part = str(part)\n",
    "        if part in sample_id_set:\n",
    "            return part\n",
    "\n",
    "    # 2) Regex extraction (PB_/IL_...) if the folder name contains more text\n",
    "    for part in path.parts[::-1]:\n",
    "        m = _SAMPLE_ID_RE.match(str(part))\n",
    "        if m:\n",
    "            cand = m.group(0)\n",
    "            if cand in sample_id_set:\n",
    "                return cand\n",
    "\n",
    "    # 3) Folder equals `sample` name (only if it maps to a single sample-id)\n",
    "    for part in path.parts[::-1]:\n",
    "        p = str(part)\n",
    "        if p in sample_to_sample_ids and len(sample_to_sample_ids[p]) == 1:\n",
    "            return sample_to_sample_ids[p][0]\n",
    "\n",
    "    return None\n",
    "\n",
    "def fasta_bp(path: Path) -> int:\n",
    "    \"\"\"Sum sequence lengths in a FASTA (supports .gz); ignores headers.\"\"\"\n",
    "    opener = gzip.open if path.suffix == \".gz\" else open\n",
    "    total = 0\n",
    "    with opener(path, \"rt\") as fh:\n",
    "        for line in fh:\n",
    "            if not line or line.startswith(\">\"):\n",
    "                continue\n",
    "            total += len(line.strip())\n",
    "    return int(total)\n",
    "\n",
    "# 1) Collect candidates, keep best FASTA per (sample-id, mag-id)\n",
    "best = {}\n",
    "orphan_hits = []  # (mag-id, path) where sample-id couldn't be inferred\n",
    "\n",
    "for root in SEARCH_ROOTS:\n",
    "    if not root.exists():\n",
    "        continue\n",
    "\n",
    "    for pat in FASTA_PATTERNS:\n",
    "        for fp in root.rglob(pat):\n",
    "            mag_id = match_mag_id_from_file(fp)\n",
    "            if mag_id is None:\n",
    "                continue\n",
    "\n",
    "            sample_id = infer_sample_id_from_path(fp)\n",
    "            if sample_id is None:\n",
    "                orphan_hits.append((mag_id, str(fp)))\n",
    "                continue\n",
    "\n",
    "            key = (sample_id, mag_id)\n",
    "\n",
    "            # If duplicates exist, keep the largest file on disk (usually the final MAG FASTA).\n",
    "            try:\n",
    "                cur_size = fp.stat().st_size\n",
    "            except OSError:\n",
    "                cur_size = -1\n",
    "\n",
    "            prev = best.get(key)\n",
    "            if prev is None:\n",
    "                best[key] = fp\n",
    "            else:\n",
    "                try:\n",
    "                    prev_size = prev.stat().st_size\n",
    "                except OSError:\n",
    "                    prev_size = -1\n",
    "                if cur_size > prev_size:\n",
    "                    best[key] = fp\n",
    "\n",
    "if orphan_hits:\n",
    "    print(\n",
    "        f\"Note: {len(orphan_hits)} FASTA hits matched a metadata mag-id but sample-id couldn't be inferred from the path.\\n\"\n",
    "        \"      They will be ignored for merging because we merge on (sample-id, mag-id).\"\n",
    "    )\n",
    "\n",
    "# 2) Compute genome sizes (bp) for selected FASTA files\n",
    "rows = []\n",
    "for (sample_id, mag_id), fp in sorted(best.items()):\n",
    "    rows.append(\n",
    "        {\n",
    "            \"sample-id\": sample_id,\n",
    "            \"mag-id\": mag_id,\n",
    "            \"technique_gs\": infer_technique(sample_id),\n",
    "            \"size_bp\": fasta_bp(fp),\n",
    "            \"fasta_path\": str(fp),\n",
    "        }\n",
    "    )\n",
    "\n",
    "genome_sizes = pd.DataFrame(rows)\n",
    "print(\"Computed genome sizes for (sample-id, mag-id) pairs:\", len(genome_sizes))\n",
    "genome_sizes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9842e860",
   "metadata": {},
   "source": [
    "### Step 4. QC + merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f69332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4. QC + merge (do not modify metadata in-place)\n",
    "\n",
    "# Basic sanity check: if this is empty, the FASTA scan didn't match metadata.\n",
    "if genome_sizes.empty:\n",
    "    raise RuntimeError(\n",
    "        \"No FASTA files matched metadata (sample-id + mag-id).\\n\"\n",
    "        \"Double-check SEARCH_ROOTS and whether FASTA filenames start with mag-id.\"\n",
    "    )\n",
    "\n",
    "print(\"technique_gs (from FASTA inference) value_counts:\")\n",
    "print(genome_sizes[\"technique_gs\"].value_counts(dropna=False))\n",
    "\n",
    "# Quick diagnostic: do we at least overlap in mag-id space?\n",
    "meta_mags = set(metadata[\"mag-id\"].astype(str).str.strip())\n",
    "gs_mags = set(genome_sizes[\"mag-id\"].astype(str).str.strip())\n",
    "inter = len(meta_mags & gs_mags)\n",
    "print(\"\\nmag-id intersection:\", inter, \"/\", len(meta_mags), \"(metadata)\")\n",
    "\n",
    "if inter == 0:\n",
    "    raise RuntimeError(\n",
    "        \"No overlap between FASTA-derived mag-ids and metadata mag-ids.\\n\"\n",
    "        \"This usually means you're scanning the wrong folder, or FASTA filenames don't begin with mag-id.\"\n",
    "    )\n",
    "\n",
    "# Merge on a copy to keep shared objects unchanged.\n",
    "base_meta = metadata.copy()\n",
    "base_meta[\"sample-id\"] = base_meta[\"sample-id\"].astype(str).str.strip()\n",
    "base_meta[\"mag-id\"] = base_meta[\"mag-id\"].astype(str).str.strip()\n",
    "\n",
    "gs = genome_sizes.copy()\n",
    "gs[\"sample-id\"] = gs[\"sample-id\"].astype(str).str.strip()\n",
    "gs[\"mag-id\"] = gs[\"mag-id\"].astype(str).str.strip()\n",
    "\n",
    "# Keep only the columns that will be used downstream.\n",
    "metadata_gs = base_meta.merge(\n",
    "    gs[[\"sample-id\", \"mag-id\", \"technique_gs\", \"size_bp\"]],\n",
    "    on=[\"sample-id\", \"mag-id\"],\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "\n",
    "print(\"metadata_gs rows:\", len(metadata_gs))\n",
    "print(\"Missing size_bp:\", int(metadata_gs[\"size_bp\"].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fd7308",
   "metadata": {},
   "source": [
    "### Step 5. Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772dc1b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 5. Summaries\n",
    "\n",
    "# One row per MAG with a computed size.\n",
    "df_mag = (\n",
    "    metadata_gs\n",
    "    .dropna(subset=[\"size_bp\", \"technique_gs\"])\n",
    "    .loc[:, [\"mag-id\", \"sample-id\", \"sample\", \"technique_gs\", \"size_bp\"]]\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "if df_mag.empty:\n",
    "    raise RuntimeError(\"No MAGs with `size_bp` available after merge. Check Step 3/4 matching.\")\n",
    "\n",
    "df_mag[\"size_kbp\"] = df_mag[\"size_bp\"] / 1e3\n",
    "\n",
    "# Stable ordering for plots (preferred: Illumina then PacBio).\n",
    "preferred = [\"Illumina\", \"PacBio\"]\n",
    "tech_order = [t for t in preferred if t in set(df_mag[\"technique_gs\"])]\n",
    "tech_order += [t for t in sorted(df_mag[\"technique_gs\"].unique()) if t not in tech_order]\n",
    "\n",
    "summary = (\n",
    "    df_mag.groupby(\"technique_gs\")[\"size_kbp\"]\n",
    "    .agg(\n",
    "        n=\"count\",\n",
    "        mean=\"mean\",\n",
    "        median=\"median\",\n",
    "        q25=lambda s: s.quantile(0.25),\n",
    "        q75=lambda s: s.quantile(0.75),\n",
    "        min=\"min\",\n",
    "        max=\"max\",\n",
    "    )\n",
    "    .reindex(tech_order)\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "summary\n",
    "\n",
    "# Optional QC: inspect extremes (smallest / largest assembled MAGs)\n",
    "df_mag.sort_values(\"size_bp\").head(10)\n",
    "\n",
    "df_mag.sort_values(\"size_bp\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f975a4f",
   "metadata": {},
   "source": [
    "### Step 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e012a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 6. Visualizations\n",
    "\n",
    "# -----------------------------\n",
    "# 6.1 Genome size distributions\n",
    "# -----------------------------\n",
    "LOG = True            # log scale where applicable\n",
    "FOCUS_MAX_KBP = None  # e.g. 1000 to zoom into <= 1000 Kbp\n",
    "\n",
    "df_plot = df_mag.copy()\n",
    "if FOCUS_MAX_KBP is not None:\n",
    "    df_plot = df_plot.loc[df_plot[\"size_kbp\"] <= FOCUS_MAX_KBP].copy()\n",
    "\n",
    "# Histogram (density) — log-bins make size distributions easier to compare\n",
    "x = df_plot[\"size_kbp\"].to_numpy()\n",
    "x_pos = x[x > 0]\n",
    "bins = (\n",
    "    np.logspace(np.log10(x_pos.min()), np.log10(x_pos.max()), 35)\n",
    "    if LOG and x_pos.size and x_pos.max() > x_pos.min()\n",
    "    else 35\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(\n",
    "    data=df_plot,\n",
    "    x=\"size_kbp\",\n",
    "    hue=\"technique_gs\",\n",
    "    element=\"step\",\n",
    "    stat=\"density\",\n",
    "    common_norm=False,\n",
    "    bins=bins,\n",
    ")\n",
    "if LOG:\n",
    "    plt.xscale(\"log\")\n",
    "plt.xlabel(\"Genome size (Kbp)\" + (\" [log]\" if LOG else \"\"))\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Genome size distribution by technique (Kbp)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) Boxplot + jittered points\n",
    "plt.figure(figsize=(6, 4.5))\n",
    "\n",
    "data = [df_mag.loc[df_mag[\"technique_gs\"] == t, \"size_kbp\"].dropna().values\n",
    "        for t in tech_order]\n",
    "\n",
    "# --- boxplot (no color) ---\n",
    "bp = plt.boxplot(\n",
    "    data,\n",
    "    labels=tech_order,\n",
    "    showfliers=False,\n",
    "    widths=0.55,\n",
    "    medianprops=dict(color=\"red\", linewidth=2.2),\n",
    "    boxprops=dict(linewidth=1.4),\n",
    "    whiskerprops=dict(linewidth=1.4),\n",
    "    capprops=dict(linewidth=1.4),\n",
    ")\n",
    "\n",
    "for med in bp[\"medians\"]:\n",
    "    med.set_zorder(10)\n",
    "\n",
    "# --- overlay points (jitter, colored) ---\n",
    "rng = np.random.default_rng(0)\n",
    "color_map = {\"PacBio\": \"C0\", \"Illumina\": \"C1\"}\n",
    "\n",
    "for i, t in enumerate(tech_order, start=1):\n",
    "    y = df_mag.loc[df_mag[\"technique_gs\"] == t, \"size_kbp\"].dropna().values\n",
    "    if y.size == 0:\n",
    "        continue\n",
    "    x = i + rng.uniform(-0.18, 0.18, size=y.size)\n",
    "    plt.scatter(\n",
    "        x, y,\n",
    "        s=18, alpha=0.6, linewidths=0,\n",
    "        color=color_map.get(t, \"C2\"),  # fallback color for unexpected labels\n",
    "        zorder=2\n",
    "    )\n",
    "\n",
    "if LOG:\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "plt.ylabel(\"Genome size (Kbp)\" + (\" [log]\" if LOG else \"\"))\n",
    "plt.title(\"Genome size by technique\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"data/Visualizations/Genomesize.svg\", transparent=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ECDF\n",
    "plt.figure(figsize=(7.5, 5))\n",
    "sns.ecdfplot(data=df_plot, x=\"size_kbp\", hue=\"technique_gs\")\n",
    "if LOG:\n",
    "    plt.xscale(\"log\")\n",
    "plt.xlabel(\"Genome size (Kbp)\" + (\" [log]\" if LOG else \"\"))\n",
    "plt.ylabel(\"ECDF\")\n",
    "plt.title(\"ECDF of genome sizes by technique (Kbp)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 6.2 Plot by sample category (if present in metadata)\n",
    "# -----------------------------\n",
    "if \"category\" in metadata_gs.columns:\n",
    "    df_cat = (\n",
    "        metadata_gs\n",
    "        .dropna(subset=[\"size_bp\", \"technique_gs\", \"category\"])\n",
    "        .loc[:, [\"category\", \"technique_gs\", \"size_bp\"]]\n",
    "        .copy()\n",
    "    )\n",
    "    df_cat[\"size_kbp\"] = df_cat[\"size_bp\"] / 1e3\n",
    "\n",
    "    plt.figure(figsize=(11, 5.5))\n",
    "    sns.boxplot(data=df_cat, x=\"category\", y=\"size_kbp\", hue=\"technique_gs\", showfliers=False)\n",
    "    if LOG:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.xlabel(\"Category\")\n",
    "    plt.ylabel(\"Genome size (Kbp)\" + (\" [log]\" if LOG else \"\"))\n",
    "    plt.title(\"Genome size by category and technique\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Note: `category` column not found in metadata_gs — skipping category-based plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7120b057",
   "metadata": {},
   "source": [
    "### Step 7. Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae89481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 7. Exports\n",
    "\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Core outputs\n",
    "metadata_gs.to_csv(out_dir / \"Metadata_Extended_with_genome_size.tsv\", sep=\"\\t\", index=False)\n",
    "genome_sizes.to_csv(out_dir / \"genome_sizes_from_fasta.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Summaries\n",
    "summary.to_csv(out_dir / \"genome_size_summary_by_technique.tsv\", sep=\"\\t\")\n",
    "mags_per_sample.to_csv(out_dir / \"mag_yield_per_sample.tsv\", sep=\"\\t\", index=False)\n",
    "tech_by_sample.to_csv(out_dir / \"sample_technique_coverage.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Wrote outputs to:\", out_dir.resolve())\n",
    "mags_per_run.to_csv(out_dir / \"mag_yield_per_run.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d689432e-8c76-4662-ae97-25788ede1cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QIIME 2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
